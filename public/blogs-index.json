{
  "generatedAt": "2025-12-17T01:08:10.369Z",
  "totalBlogs": 284,
  "blogs": [
    {
      "slug": "llama-cpp-oct2025",
      "path": "blogs/ecosystems-and-partners/llama-cpp-oct2025",
      "category": "ecosystems-and-partners",
      "title": "Accelerating llama.cpp on AMD Instinct MI300X",
      "date": "Dec 11, 2025",
      "author": "Pei Zhang, Deepan Sekar, Eliot Li, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/llama-cpp-oct2025-thumbnail.webp",
      "tags": [
        "AI/ML",
        "C++",
        "GenAI",
        "LLM",
        "Performance",
        "Serving"
      ],
      "description": "Learn more about the superior performance of llama.cpp on Instinct platforms.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "swinunetr-inference-optimization",
      "path": "blogs/artificial-intelligence/swinunetr-inference-optimization",
      "category": "artificial-intelligence",
      "title": "Medical Imaging on MI300X: SwinUNETR Inference Optimization",
      "date": "10 Dec 2025",
      "author": "Joaquin Rives Gambin",
      "thumbnail": "images/thumbnail_swinunet_inference.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Computer Vision",
        "Optimization",
        "PyTorch"
      ],
      "description": "A practical guide to optimizing SwinUNETR inference on AMD Instinct™ MI300X GPUs for fast 3D segmentation of tumors in medical imaging.",
      "language": "English",
      "verticals": [
        "AI, Developers, Data Science, HPC"
      ]
    },
    {
      "slug": "autonomous-driving",
      "path": "blogs/artificial-intelligence/autonomous-driving",
      "category": "artificial-intelligence",
      "title": "Accelerating Autonomous Driving Model Training on AMD ROCm™ Software",
      "date": "08 Dec 2025",
      "author": "Fuwei Yang, Mingjie Lu, Bin Ding, Fan Wang, Treemann Zheng, Zhaodong Bing, Dong Li, Emad Barsoum",
      "thumbnail": "images/autodrive_rocm.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how to deploy AMD GPUs for high-performance autonomous driving related model training with ROCm optimization.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "scaling-ai-inference",
      "path": "blogs/artificial-intelligence/scaling-ai-inference",
      "category": "artificial-intelligence",
      "title": "Scaling AI Inference Performance with vLLM on AMD Instinct MI355X GPUs",
      "date": "08 Dec 2025",
      "author": "Jouni Hartikainen, Aarne Talman, Reima Karhila, Teemu Virolainen, Mikko Tukiainen, Bishwo Adhikari,  Xavier Aguilar Fruto, Chun Fang, Stig-Arne Gronroos, Markus Hartikainen, Mustafa Khalid Masood, Olga Miroshnichenko,  Tres Popp, Tuukka Sarvi, Olha Shkaravska,  Jin Tao, Matti Varjokallio, Nico Holmberg, Jaakko Vainio, Faisal Azhar",
      "thumbnail": "images/vllm_blog_thumbnail.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Performance"
      ],
      "description": "Explore how MI355X performs against B200 in vLLM benchmarks across DeepSeek-R1, GPT-OSS-120B, Qwen3-235B and Llama-3.3-70B.",
      "language": "English",
      "verticals": [
        "AI, HPC, Developers"
      ]
    },
    {
      "slug": "sand-math",
      "path": "blogs/artificial-intelligence/sand-math",
      "category": "artificial-intelligence",
      "title": "Building a State-of-the-Art 32 Billion Reasoning Model with Only Synthetic Data on AMD GPUs",
      "date": "6 Dec 2025",
      "author": "Chaitanya Manem, Pratik Prabhanjan Brahma, Prakamya Mishra, Zicheng Liu, Emad Barsoum",
      "thumbnail": "images/sand-math-thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how to build a State-of-the-art reasoning model that beats Qwen3-32B using only synthetic data and SFT on AMD Instinct™ GPUs—fast, simple, and scalable.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "dgl-in-depth",
      "path": "blogs/artificial-intelligence/dgl-in-depth",
      "category": "artificial-intelligence",
      "title": "DGL in Depth: SE(3)-Transformer on ROCm 7",
      "date": "5 Dec 2025",
      "author": "Anuya Welling, James E. T. Smith, Geoffrey C. Martin-Noble, Tres Popp, Eliot Li, Mukhil Azhagan Mallaiyan Sathiaseelan, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/se3transformer-thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Inform the AI community about running SE(3)-Transformer with DGL on AMD Instinct platforms.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "taichi_mi300x",
      "path": "blogs/artificial-intelligence/taichi_mi300x",
      "category": "artificial-intelligence",
      "title": "Modernizing Taichi Lang to LLVM 20 for MI355X GPU Acceleration",
      "date": "04 Dec 2025",
      "author": "Tiffany Mintz, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/taichi_blog_thumbnail.webp",
      "tags": [
        "AI/ML",
        "Scientific Computing"
      ],
      "description": "Power your next AI application or graphics simulation with high-performance GPU/CPU computing in Python with Taichi Lang.",
      "language": "English",
      "verticals": [
        "AI, HPC"
      ]
    },
    {
      "slug": "hpc-agent-rag",
      "path": "blogs/artificial-intelligence/hpc-agent-rag",
      "category": "artificial-intelligence",
      "title": "HPC Coding Agent - Part 1: Combining GLM-powered Cline and RAG Using MCP",
      "date": "3 Dec 2025",
      "author": "Johanna Yang, Albin Toft",
      "thumbnail": "images/rag-robot-thumbnail.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Scientific Computing",
        "GenAI"
      ],
      "description": "Build an HPC RAG agent on AMD Instinct GPUs using GLM-4.6, Cline and ChromaDB.",
      "language": "English",
      "verticals": [
        "HPC, AI"
      ]
    },
    {
      "slug": "tyr-the-pruner",
      "path": "blogs/artificial-intelligence/tyr-the-pruner",
      "category": "artificial-intelligence",
      "title": "Týr-the-Pruner: Search-based Global Structural Pruning for LLMs",
      "date": "03 Dec 2025",
      "author": "Guanchen Li, Yixing Xu, Zeping Li, Ji Liu, Xuanwu Yin, Dong Li, Emad Barsoum",
      "thumbnail": "images/AI-generated.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "This blog introduces Týr-the-Pruner, a search-based, end-to-end framework for global structural pruning of large language models (LLMs).",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "ROCm7-MI355X-training-performance",
      "path": "blogs/artificial-intelligence/ROCm7-MI355X-training-performance",
      "category": "artificial-intelligence",
      "title": "Optimizing LLM Workloads: AMD Instinct MI355X GPUs Drive Competitive Performance",
      "date": "2 Dec 2025",
      "author": "Joyce Zhang, Jared Bowden, Shubin Zhao, Keith Anderson, Kajsa Arnold, Andrew Ma, Sriranjani Ramasubramanian, Yao Fu, Wen Xie, Vidushi Goyal, Yanyuan Qin, Andy Ye, Deval Shah, Lorri Rao, Subhajit Dutta Chowdhury, Gene Su",
      "thumbnail": "images/Training_rocm7.webp",
      "tags": [
        "AI/ML",
        "PyTorch",
        "JAX",
        "Performance",
        "Optimization",
        "GenAI"
      ],
      "description": "Explore ROCm 7.0’s AI training boost! See how MI355X accelerates JAX and PyTorch frameworks to unlock faster and efficient LLM scaling.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vlm-finetune-rocm",
      "path": "blogs/artificial-intelligence/vlm-finetune-rocm",
      "category": "artificial-intelligence",
      "title": "VLM Fine-Tuning for Robotics on AMD Enterprise AI Suite",
      "date": "28 Nov 2025",
      "author": "Levent Guner, Teemu Karkkainen, Shaghayegh Roohi, Niko Vuokko",
      "thumbnail": "images/vlm-robo-ft-thumbnail.webp",
      "tags": [
        "Fine-Tuning"
      ],
      "description": "Fine-tune OpenCLIP with Bridge Data V2 on ROCm to enable robotics related fine-tuning",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "hunyuan-gamecraft",
      "path": "blogs/artificial-intelligence/hunyuan-gamecraft",
      "category": "artificial-intelligence",
      "title": "Exploring Gameplay Video Generation with Hunyuan-GameCraft on AMD Instinct GPUs",
      "date": "27 Nov 2025",
      "author": "Kristoffer Peyron, Johanna Yang",
      "thumbnail": "images/green_field_thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Diffusion Model"
      ],
      "description": "Learn to generate dynamic, action-controllable gameplay videos from single images using Hunyuan-GameCraft on AMD Instinct MI300X GPUs with ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "rocm-finetune-protein",
      "path": "blogs/artificial-intelligence/rocm-finetune-protein",
      "category": "artificial-intelligence",
      "title": "Fine-Tune LLMs for Proteins with AMD Enterprise AI Suite",
      "date": "27 Nov 2025",
      "author": "Juho Kerttula, Levent Guner",
      "thumbnail": "images/protein-llm-thumbnail.webp",
      "tags": [
        "Fine-Tuning"
      ],
      "description": "Fine-tune Llama 3.1 8B with ROCm for advanced protein sequence insights in bioinformatics",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "wan-flow-grpo",
      "path": "blogs/artificial-intelligence/wan-flow-grpo",
      "category": "artificial-intelligence",
      "title": "Using Reinforcement Learning to Fix Text in AI-Generated Videos",
      "date": "25 Nov 2025",
      "author": "Arttu Niemela, Albin Toft",
      "thumbnail": "images/thumbnail_prompt1.webp",
      "tags": [
        "GenAI",
        "Reinforcement Learning",
        "Fine-Tuning",
        "AI/ML"
      ],
      "description": "Demonstrates how Flow-GRPO can be used to fine-tune Wan models to better generate text in videos by covering background, set up and some examples of training runs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vllm-moe-guide",
      "path": "blogs/software-tools-optimization/vllm-moe-guide",
      "category": "software-tools-optimization",
      "title": "The vLLM MoE Playbook: A Practical Guide to TP, DP, PP and Expert Parallelism",
      "date": "24 Nov 2025",
      "author": "Pin Siang Tan, Hongxia Yang, Peng Sun, Andy Luo, Jun Kang Chow, Ye Hur Cheong, Tun Jian Tan",
      "thumbnail": "images/MoE_Parallel.webp",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Serving"
      ],
      "description": "Learn how to combine TP, DP, PP, and EP for MoE models. Discover proven strategies to maximize performance on your vLLM deployments.",
      "language": "English",
      "verticals": [
        "AI, Developers"
      ]
    },
    {
      "slug": "hunyuanworld-voyager-inference",
      "path": "blogs/artificial-intelligence/hunyuanworld-voyager-inference",
      "category": "artificial-intelligence",
      "title": "Inference with HunyuanWorld-Voyager on AMD Instinct GPUs",
      "date": "21 Nov 2025",
      "author": "Johanna Yang, Kristoffer Peyron",
      "thumbnail": "images/elk_thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Diffusion Model"
      ],
      "description": "Learn how to run inference with HunyuanWorld-Voyager, a state-of-the-art 3D world model, on AMD Instinct MI300X GPUs using ROCm for efficient video generation and prediction.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mattergen",
      "path": "blogs/artificial-intelligence/mattergen",
      "category": "artificial-intelligence",
      "title": "Accelerating AI-Driven Crystalline Materials Design with MatterGen on AMD Instinct MI300X",
      "date": "21 Nov 2025",
      "author": "Sopiko Kurdadze",
      "thumbnail": "images/mattergen-crystals.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Scientific Computing"
      ],
      "description": "Learn how to run a generative model for inorganic material design with MatterGen on MI300X.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "enterprise-ai-aims",
      "path": "blogs/artificial-intelligence/enterprise-ai-aims",
      "category": "artificial-intelligence",
      "title": "AMD Inference Microservice (AIM): Production-Ready Inference on AMD Instinct GPUs",
      "date": "17 Nov 2025",
      "author": "Andy Allred, William Anzen, Alexander Aurell, Aravind Kumar Rao Bappanadu, Thomas Bergstrom, Sander Bijl de Vroe, Marc Dillon, Stanislau Fink, Alexander Finn, Mark van Heeswijk, Andrey Ivannikov, Teemu Karkkainen, Shashank Kashyap , Juho Kerttula, Miikael Leskinen, Hari Nair, Mika Ranta, Mario Reiser, Alex Saliniemi, Rui Sampaio, Harry Souris, Antti-Ville Suni, Robert Talling, Juho Vainio, Mikko Vilenius, Yu Wang, Bo Zhang",
      "thumbnail": "images/Blog_Thumbnail_AIMs.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM",
        "Performance",
        "Serving",
        "Kubernetes"
      ],
      "description": "Learn how AIM delivers efficient, scalable inference on AMD Instinct GPUs and see how it simplifies deployment, optimization, and operations.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "enterprise-ai-suite",
      "path": "blogs/artificial-intelligence/enterprise-ai-suite",
      "category": "artificial-intelligence",
      "title": "AMD Enterprise AI Suite: Open Infrastructure for Production AI",
      "date": "17 Nov 2025",
      "author": "Yu Wang, Alexander Finn, Nicola Tan, Sebastian Andersson, Brayden Mahdavi, Mathias Lehtinen",
      "thumbnail": "images/Blog_Thumbnail_Enterprise_AI_Suite.webp",
      "tags": [
        "GenAI",
        "LLM",
        "Performance",
        "Kubernetes"
      ],
      "description": "Explore an open, GPU-optimized platform to build, deploy, and scale enterprise AI workloads on AMD Instinct with production-ready performance.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "cupy-v13",
      "path": "blogs/artificial-intelligence/cupy-v13",
      "category": "artificial-intelligence",
      "title": "Plug-and-Play CuPy on ROCm: Data Analytic Acceleration Made Simple",
      "date": "14 Nov 2025",
      "author": "Grant Pinkert, Eliot Li",
      "thumbnail": "images/cuPy-ROCm7-thumbnail.webp",
      "tags": [
        "Scientific Computing",
        "AI/ML",
        "Time Series",
        "Optimization"
      ],
      "description": "Learn about how to enhance your analytics project with the latest AMD CuPy release.",
      "language": "English",
      "verticals": [
        "Data Science, AI"
      ]
    },
    {
      "slug": "democratizing-multicloud-skypi",
      "path": "blogs/ecosystems-and-partners/democratizing-multicloud-skypi",
      "category": "ecosystems-and-partners",
      "title": "Democratizing AI Compute with AMD Using SkyPilot",
      "date": "13 Nov 2025",
      "author": "Pratik Mishra, Paul Hartke, Romil Bhardwaj, Zongheng Yang, Zhanghao Wu",
      "thumbnail": "images/amd-multicloud-skypilot.webp",
      "tags": [
        "AI/ML",
        "PyTorch",
        "Kubernetes"
      ],
      "description": "Learn how SkyPilot integrates with AMD open AI stack to enable seamless multi-cloud deployment and simplifies NVIDIA-to-AMD GPU migration.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "hipvs",
      "path": "blogs/software-tools-optimization/hipvs",
      "category": "software-tools-optimization",
      "title": " Accelerating Vector Search: hipVS and hipRAFT on AMD",
      "date": "13 Nov 2025",
      "author": "Sukriti Choudhary, Sujin Philip, Kevin Joseph, Fabricio Flores, Eliot Li, Lalith Narasimhan, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/hipvs_thumbnail.webp",
      "tags": [
        "Scientific Computing",
        "Optimization",
        "Recommendation Systems"
      ],
      "description": "Learn how hipVS accelerates vector search on AMD Instinct GPUs, with notebook demos for semantic search, RAG, and recommendation systems.",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "mlperf-training-v5.1",
      "path": "blogs/artificial-intelligence/mlperf-training-v5.1",
      "category": "artificial-intelligence",
      "title": "Technical Dive into AMD MLPerf Training v5.1 Submission",
      "date": "12 Nov 2025",
      "author": "Meena Arunachalam, Miro Hodak, Ravi Dwivedula, Sarthak Arora, Sathish Sanjeevi, Su Ann Chong, Karan Verma, Eliot Li",
      "thumbnail": "images/mlperf-training-v5.1-thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Performance",
        "Optimization",
        "Fine-Tuning",
        "MLPerf",
        "MLPerf Training"
      ],
      "description": "Learn about the technical details of how AMD achieved the results in the MLPerf Training v5.1 submission.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mlperf-training5.1-repro",
      "path": "blogs/artificial-intelligence/mlperf-training5.1-repro",
      "category": "artificial-intelligence",
      "title": "Reproduce AMD MLPerf Training v5.1 Submission Result",
      "date": "12 Nov 2025",
      "author": "Meena Arunachalam, Miro Hodak, Ravi Dwivedula, Sarthak Arora, Sathish Sanjeevi, Su Ann Chong, Karan Verma, Eliot Li",
      "thumbnail": "images/mlperf-training5.1-repro-thumbnail.webp",
      "tags": [
        "AI/ML",
        "Fine-Tuning",
        "GenAI",
        "Optimization",
        "Performance",
        "MLPerf",
        "MLPerf Training"
      ],
      "description": "Learn how to reproduce AMD's MLPerf Training v5.1 submission result.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "wide-ep-deepseek",
      "path": "blogs/software-tools-optimization/wide-ep-deepseek",
      "category": "software-tools-optimization",
      "title": "Practical, Fault‑Robust Distributed Inference for DeepSeek on AMD MI300X",
      "date": "12 Nov 2025",
      "author": "Peng Sun, Andy Luo, Gilbert Lei, Lingpeng Jin, Carlus Huang, Duyi Wang, Mingzhi Liu, Di Tian, Bill He, Jun Chen, Yutong Wu, Jiahao Zhou, Niko Ma",
      "thumbnail": "images/thumbnail.webp",
      "tags": [
        "AI/ML",
        "Performance",
        "Optimization",
        "Serving"
      ],
      "description": "Learn how a small-radius expert parallel design with prefill–decode disaggregation enables scalable, fault-isolated LLM inference on AMD Instinct™ MI300X clusters.",
      "language": "English",
      "verticals": [
        "AI, Systems"
      ]
    },
    {
      "slug": "geoarches-training",
      "path": "blogs/artificial-intelligence/geoarches-training",
      "category": "artificial-intelligence",
      "title": "Training AI Weather Forecasting Models on AMD Instinct",
      "date": "10 Nov 2025",
      "author": "Luka Tsabadze, Rahul Biswas, Pauli Pihajoki, Daniel Warna, Baiqiang Xia, Sopiko Kurdadze",
      "thumbnail": "images/geoarches_blog_thumbnail.webp",
      "tags": [
        "AI/ML",
        "PyTorch",
        "Fine-Tuning"
      ],
      "description": "Learn how deterministic and generative AI models for synoptic-scale weather forecasting are trained efficiently on AMD Instinct MI300X GPUs using the ROCm and GeoArches tools.",
      "language": "English",
      "verticals": [
        "AI, Data Science"
      ]
    },
    {
      "slug": "hipblaslt_offline_tuning",
      "path": "blogs/artificial-intelligence/hipblaslt_offline_tuning",
      "category": "artificial-intelligence",
      "title": "Day 0 Developer Guide: hipBLASLt Offline GEMM Tuning Script",
      "date": "5 Nov 2025",
      "author": "Han Lin, Spandan Tiwari, Xinjun Niu, Chao Li, Wei Luo, Junyan Yang, Carson Liao, Chunhung Wang, Ashish Sirasao",
      "thumbnail": "images/hipblaslt_offline_tuning.webp",
      "tags": [
        "Performance",
        "hipBLASLt",
        "LLM",
        "GEMM Tuning"
      ],
      "description": "Learn how to improve model performance with hipBLASLt offline tuning in our easy-to-use Day 0 tool for developers to optimize GEMM efficiency",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "rocm-7.1",
      "path": "blogs/ecosystems-and-partners/rocm-7.1",
      "category": "ecosystems-and-partners",
      "title": "Continuing the Momentum: Refining ROCm for the Next Wave of AI and HPC",
      "date": "5 Nov 2025",
      "author": "Anshul Gupta, Liam Berry, Saad Rahim",
      "thumbnail": "images/blog7.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "ROCm 7.1 builds on 7.0’s AI and HPC advances with faster performance, stronger reliability, and streamlined tools for developers and system builders.",
      "language": "English",
      "verticals": [
        "Developers, AI, HPC"
      ]
    },
    {
      "slug": "rag-pipeline-vllm",
      "path": "blogs/artificial-intelligence/rag-pipeline-vllm",
      "category": "artificial-intelligence",
      "title": "Retrieval Augmented Generation (RAG) with vLLM, LangChain and Chroma",
      "date": "04 Nov 2025",
      "author": "Rasmus Larsson, Emelie Wahlstrom, Saroosh Shabbir",
      "thumbnail": "images/thumbnail_rag.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn AI-powered knowledge retrieval that enriches prompts with proprietary data to deliver accurate and context-aware answers",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "primus-SaFE",
      "path": "blogs/software-tools-optimization/primus-SaFE",
      "category": "software-tools-optimization",
      "title": "Stability at Scale: AMD’s Full‑Stack Platform for Large‑Model Training",
      "date": "4 Nov 2025",
      "author": "Chaojun Hou, Lei Wei, Liz Li, Yao Fu, Andy Luo, Zhenyu Gu",
      "thumbnail": "images/primus-safe-thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Primus streamlines LLM training on AMD GPUs with unified configs, multi-backend support, preflight validation, and structured logging.",
      "language": "English",
      "verticals": [
        "AI, Developers"
      ]
    },
    {
      "slug": "mxfp4-mxfp6-quantization",
      "path": "blogs/software-tools-optimization/mxfp4-mxfp6-quantization",
      "category": "software-tools-optimization",
      "title": "High-Accuracy MXFP4, MXFP6, and Mixed-Precision Models on AMD GPUs",
      "date": "29 Oct 2025",
      "author": "Lin Zhao, Felix Marty, Spandan Tiwari, Wei Luo, Bowen Bao, Xinjun Niu, Zhaofeng Zhang, Haoyang Li, Ke Wang, Ashish Sirasao",
      "thumbnail": "images/mxfp4.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "Optimization"
      ],
      "description": "Learn to leverage AMD Quark for efficient MXFP4/MXFP6 quantization on AMD Instinct accelerators with high accuracy retention.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "nitro-e",
      "path": "blogs/artificial-intelligence/nitro-e",
      "category": "artificial-intelligence",
      "title": "Nitro-E: A 304M Diffusion Transformer Model for High Quality Image Generation",
      "date": "24 Oct 2025",
      "author": "Tong Shen, Jingai Yu, Dong Zhou, Dong Li, Emad Barsoum",
      "thumbnail": "images/nitro-e-thumbnail.webp",
      "tags": [
        "PyTorch",
        "Diffusion Model"
      ],
      "description": "Nitro-E is an extremely lightweight diffusion transformer model for high-quality image generation with only 304M paramters.",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "stx-b0t",
      "path": "blogs/artificial-intelligence/stx-b0t",
      "category": "artificial-intelligence",
      "title": "STX-B0T: AI Robot Assistant Powered by RyzenAI and ROCm",
      "date": "23 Oct 2025",
      "author": "Justin Chu, Yosi Hatekar, Vivian Cheng, Hyunji Kim, Alex Bogdan",
      "thumbnail": "images/stxb0t_cartoonized.webp",
      "tags": [
        "AI/ML",
        "Computer Vision"
      ],
      "description": "STX-B0T explores the potential of RyzenAI PCs to power robotics applications on NPU+GPU. This blog demonstrates how our hardware and software interoperate to unlock real-time perception.",
      "language": "English",
      "verticals": [
        "AI, Developers"
      ]
    },
    {
      "slug": "profiling-guide/advanced",
      "path": "blogs/software-tools-optimization/profiling-guide/advanced",
      "category": "software-tools-optimization",
      "title": "AMD GPU profiling guide - Advanced Usage",
      "date": "23 October 2025",
      "author": "Gina Sitaraman, Thomas Gibson, Luka Stanisic, Giacomo Capodaglio, Alessandro Fanfarillo, Asitav Mishra",
      "thumbnail": "2025-06-25-profiling-guide.png",
      "tags": [
        "HPC",
        "Performance",
        "Optimization",
        "Profiling"
      ],
      "description": "Part 3 of our GPU profiling series guides beginners through practical steps to identify and optimize kernel bottlenecks using ROCm tools",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "pytorch-amd-gpus",
      "path": "blogs/artificial-intelligence/pytorch-amd-gpus",
      "category": "artificial-intelligence",
      "title": "Empowering Developers to Build a Robust PyTorch Ecosystem on AMD ROCm™ with Better Insights and Monitoring",
      "date": "21 Oct 2025",
      "author": "Hongxia Yang, Peng Sun, Nick Romero, Jeff Daily, Jithun Nair, Pruthvi Madugundu, Jagadish Krishnamoorthy, Srinivasan Subramanian, Eli Uriegas",
      "thumbnail": "images/pytorch_thumbnail.webp",
      "tags": [
        "AI/ML",
        "PyTorch",
        "Performance"
      ],
      "description": "Production ROCm support for N-1 to N+1 PyTorch releases is in progress. The AI Software Head-Up Dashboard shows status of PyTorch on ROCm.",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "therock",
      "path": "blogs/software-tools-optimization/therock",
      "category": "software-tools-optimization",
      "title": "ROCm 7.9 Technology Preview: ROCm Core SDK and TheRock Build System",
      "date": "20 Oct 2025",
      "author": "Dominic Widdows, Janet Tseng, Scott Todd, Chris Sosa, Saad Rahim",
      "thumbnail": "images/build_rocm_thumbnail.webp",
      "tags": [
        "C++",
        "GenAI",
        "AI/ML"
      ],
      "description": "Introduce ROCm Core SDK, and learn to install and build ROCm components easily using TheRock.",
      "language": "English",
      "verticals": [
        "AI, HPC, Developers"
      ]
    },
    {
      "slug": "kimi-k2",
      "path": "blogs/artificial-intelligence/kimi-k2",
      "category": "artificial-intelligence",
      "title": "Kimi-K2-Instruct: Enhanced Out-of-the-Box Performance on AMD Instinct MI355 Series GPUs",
      "date": "16 Oct 2025",
      "author": "Wei Cai, Fan Wu, George Wang",
      "thumbnail": "images/Kimi_thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how AMD Instinct MI355 Series GPUs deliver competitive Kimi-K2 inference with faster TTFT, lower latency, and strong throughput.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "gumiho",
      "path": "blogs/software-tools-optimization/gumiho",
      "category": "software-tools-optimization",
      "title": "Gumiho: A New Paradigm for Speculative Decoding — Earlier Tokens in a Draft Sequence Matter More",
      "date": "14 October 2025",
      "author": "Jinze Li, Yixing Xu, Xuanwu Yin, Dong Li, Emad Barsoum",
      "thumbnail": "images/gumiho-blog-2025-10-14.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Gumiho boosts LLM inference with early-token accuracy, blending serial + parallel decoding for speed, accuracy, and ROCm-optimized deployment.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "hipblaslt-offline-tuning-part2",
      "path": "blogs/software-tools-optimization/hipblaslt-offline-tuning-part2",
      "category": "software-tools-optimization",
      "title": "GEMM Tuning within hipBLASLt- Part 2",
      "date": "09 Oct 2025",
      "author": "Chia Hung, YangWen Huang, Carson Liao",
      "thumbnail": "image/thumbnail.png",
      "tags": [
        "AI/ML",
        "Developers"
      ],
      "description": "Learn how to use hipblaslt-bench for offline GEMM tuning in hipBLASLt—benchmark, save, and apply custom-tuned kernels at runtime.",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "monai-rocm",
      "path": "blogs/artificial-intelligence/monai-rocm",
      "category": "artificial-intelligence",
      "title": "Announcing MONAI 1.0.0 for AMD ROCm: Breakthrough AI Acceleration for Medical Imaging AI Models on AMD Instinct™ GPUs",
      "date": "07 Oct 2025",
      "author": "Soumitra Chatterjee, Anik Chaudhuri, Chandan Sharma, Vikas C Sajjan, Vish Vadlamani, Dominic Widdows, Phani Vaddadi",
      "thumbnail": "images/monai-hipcim-thumbnail.webp",
      "tags": [
        "AI/ML",
        "Computer Vision"
      ],
      "description": "Learn how to use Medical Open Network for Artificial Intelligence (MONAI) 1.0 on ROCm, with examples and demonstrations.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "running-swinunetr-amd",
      "path": "blogs/artificial-intelligence/running-swinunetr-amd",
      "category": "artificial-intelligence",
      "title": "Medical Imaging on MI300X: Optimized SwinUNETR for Tumor Detection",
      "date": "07 Oct 2025",
      "author": "Joaquin Rives Gambin, Vasumathi Neralla, David Björelind, Rui Sampaio",
      "thumbnail": "images/swinunetrblogthumbnail.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Computer Vision",
        "Optimization",
        "PyTorch"
      ],
      "description": "Learn how to setup, run and optimize SwinUNETR on AMD MI300X GPUs for fast medical imaging 3D segmentation of tumors using fast, large ROIs.",
      "language": "English",
      "verticals": [
        "AI, Developers, Data Science, HPC"
      ]
    },
    {
      "slug": "fp4-mixed-precision",
      "path": "blogs/artificial-intelligence/fp4-mixed-precision",
      "category": "artificial-intelligence",
      "title": "Optimizing FP4 Mixed-Precision Inference on AMD Instinct MI250 and MI300 GPUs: A Developers Perspective",
      "date": "06 Oct 2025",
      "author": "Haohui Mai, Charles Yang, George Wang",
      "thumbnail": "images/fp4.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how FP4 mixed-precision on AMD GPUs boosts inference speed and integrates seamlessly with SGLang.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "semlaflow",
      "path": "blogs/artificial-intelligence/semlaflow",
      "category": "artificial-intelligence",
      "title": "Optimizing drug discovery tools on AMD MI300X Part 2: 3D Molecular Generation with SemlaFlow",
      "date": "3 Oct 2025",
      "author": "Vasumathi Neralla, Rui Sampaio",
      "thumbnail": "images/thumbnail-semlaflow.webp",
      "tags": [
        "PyTorch",
        "Optimization"
      ],
      "description": "Learn how to set up, run, and optimize SemlaFlow, a molecular generation tool, on AMD MI300X GPUs for faster drug discovery workflows",
      "language": "English",
      "verticals": [
        "Developers"
      ]
    },
    {
      "slug": "gsplat",
      "path": "blogs/software-tools-optimization/gsplat",
      "category": "software-tools-optimization",
      "title": "Elevating 3D Scene Rendering with GSplat",
      "date": "03 Oct 2025",
      "author": "Deeksha Goplani, Ish Kool, Karthik Kashyap Thatipamula, Marco Grond, Mark Granroth Wilding, Pier Luigi Dovesi, Shaghayegh Roohi, Vish Vadlamani, Vikas C Sajjan, Phani Vaddadi",
      "thumbnail": "2025-09-30-gsplat.png",
      "tags": [
        "Computer Vision",
        "PyTorch"
      ],
      "description": "ROCm Port of GSplat - GPU accelerated rasterization of Gaussian splatting",
      "language": "English",
      "verticals": [
        "Developers"
      ]
    },
    {
      "slug": "rag-agent",
      "path": "blogs/artificial-intelligence/rag-agent",
      "category": "artificial-intelligence",
      "title": "From Ingestion to Inference: RAG Pipelines on AMD GPUs",
      "date": "2 Oct 2025",
      "author": "Lin Sun, Anuya Welling, Fabricio Flores, Eliot Li, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/rag-pipeline-thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Serving"
      ],
      "description": "Build a RAG enhanced GenAI application that improves the quality of model responses by incorporating data that is missing in the model training data.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "flashinfer",
      "path": "blogs/artificial-intelligence/flashinfer",
      "category": "artificial-intelligence",
      "title": "Enabling FlashInfer on ROCm for Accelerated LLM Serving",
      "date": "1 Oct 2025",
      "author": "Rishi Madduri, Diptorup Deb, Debasis Mandal, Clint Greene, Mukhil Azhagan Mallaiyan Sathiaseelan, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/flashinfer-thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Optimization",
        "Serving"
      ],
      "description": "FlashInfer is an open-source library for accelerating LLM serving that is now supported by ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "gpu-operator-partitioning",
      "path": "blogs/software-tools-optimization/gpu-operator-partitioning",
      "category": "software-tools-optimization",
      "title": "GPU Partitioning Made Easy: Pack More AI Workloads Using AMD GPU Operator",
      "date": "1 Oct 2025",
      "author": "Alireza Sariaslani",
      "thumbnail": "images/gpu-partitioning-thumbnail.webp",
      "tags": [
        "AI/ML",
        "Kubernetes",
        "Performance",
        "Serving"
      ],
      "description": "What’s New in AMD GPU Operator: Learn About GPU Partitioning and New Kubernetes Features",
      "language": "English",
      "verticals": [
        "Systems",
        "AI",
        "HPC"
      ]
    },
    {
      "slug": "coding-agent",
      "path": "blogs/artificial-intelligence/coding-agent",
      "category": "artificial-intelligence",
      "title": "Coding Agents on AMD GPUs: Fast LLM Pipelines for Developers",
      "date": "30 Sep 2025",
      "author": "Lin Sun, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/rocm_rag_thumbnail.webp",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI"
      ],
      "description": "Accelerate AI-assisted coding with agentic workflows on AMD GPUs. Deploy DeepSeek-V3.1 via SGLang, vLLM, or llama.cpp to power fast, scalable coding agents",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "matrix-cores-cdna",
      "path": "blogs/software-tools-optimization/matrix-cores-cdna",
      "category": "software-tools-optimization",
      "title": "Matrix Core Programming on AMD CDNA™3 and CDNA™4 architecture",
      "date": "30 Sep 2025",
      "author": "Amanzhol Salykov, Andy Luo, Carlus Huang, Peng Sun",
      "thumbnail": "images/MatrixCoresCDNAThumbnail.webp",
      "tags": [
        "AI/ML",
        "C++",
        "Linear Algebra",
        "HPC",
        "Performance",
        "Optimization",
        "Hardware"
      ],
      "description": "This blog post explains how to use Matrix Cores on CDNA3 and CDNA4 architecture, with a focus on low-precision data types such as FP16, FP8, and FP4",
      "language": "English",
      "verticals": [
        "Developers, HPC, AI, Systems"
      ]
    },
    {
      "slug": "slime",
      "path": "blogs/artificial-intelligence/slime",
      "category": "artificial-intelligence",
      "title": "Day-0 Support for the SGLang-Native RL Framework - slime on AMD Instinct™ GPUs",
      "date": "25 Sep 2025",
      "author": "Yusheng Su, Yuzhen Zhou, Jin Pan, Gowtham Ramesh, Xiaodong Yu, Jialian Wu, Ze Wang, Ximeng Sun, Jiang Liu, Hao Chen, Zicheng Liu, Emad Barsoum",
      "thumbnail": "images/1.webp",
      "tags": [
        "Reinforcement Learning",
        "AI/ML",
        "Fine-Tuning",
        "GenAI"
      ],
      "description": "Learn how to deploy slime on AMD GPUs for high-performance RL training with ROCm optimization",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "audio-driven-videogen",
      "path": "blogs/artificial-intelligence/audio-driven-videogen",
      "category": "artificial-intelligence",
      "title": "Accelerating Audio-Driven Video Generation: WAN2.2-S2V on AMD ROCm",
      "date": "24 Sep 2025",
      "author": "Johanna Yang, Kristoffer Peyron",
      "thumbnail": "images/einstein_thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Diffusion Model"
      ],
      "description": "This blog will highlight AMD ROCm’s ability to power next-generation audio-to-video models with simple, reproducible workflows.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "serving-videogen-v1",
      "path": "blogs/artificial-intelligence/serving-videogen-v1",
      "category": "artificial-intelligence",
      "title": "A Simple Design for Serving Video Generation Models with Distributed Inference",
      "date": "24 Sep 2025",
      "author": "Sopiko Kurdadze, Albin Toft",
      "thumbnail": "images/thumbnail.webp",
      "tags": [
        "AI/ML",
        "Diffusion Model",
        "GenAI",
        "Serving"
      ],
      "description": "Minimalist FastAPI + Redis + Torchrun design for serving video generation models with distributed inference.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "running-reinvent4-amd",
      "path": "blogs/artificial-intelligence/running-reinvent4-amd",
      "category": "artificial-intelligence",
      "title": "Optimizing Drug Discovery Tools on AMD MI300X Part 1: Molecular Design with REINVENT",
      "date": "19 Sep 2025",
      "author": "David Björelind, Rui Sampaio",
      "thumbnail": "images/reinvent_blog_thumbnail.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "PyTorch",
        "Optimization"
      ],
      "description": "Learn how to set up, run, and optimize REINVENT4, a molecular design tool, on AMD MI300X GPUs for faster drug discovery workflows",
      "language": "English",
      "verticals": [
        "AI, HPC, Developers"
      ]
    },
    {
      "slug": "primus-large-models",
      "path": "blogs/software-tools-optimization/primus-large-models",
      "category": "software-tools-optimization",
      "title": "An Introduction to Primus-Turbo: A Library for Accelerating Transformer Models on AMD GPUs",
      "date": "19 Sep 2025",
      "author": "Xiaobo Chen, Wen Xie, Liz Li, Yao Fu, Andy Luo, Zhenyu Gu",
      "thumbnail": "images/Primus-Turbo-Thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM",
        "PyTorch",
        "Performance"
      ],
      "description": "Primus streamlines training on AMD ROCm, from fine-tuning to massive pretraining on MI300X GPUs—faster, safer, and easier to debug",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "ai-weather-forecasting",
      "path": "blogs/artificial-intelligence/ai-weather-forecasting",
      "category": "artificial-intelligence",
      "title": "Running SOTA AI-based Weather Forecasting models on AMD Instinct",
      "date": "18 Sep 2025",
      "author": "Luka Tsabadze, Rahul Biswas, Pauli Pihajoki, Daniel Warna, Baiqiang Xia",
      "thumbnail": "images/output_thumbnail.webp",
      "tags": [
        "AI/ML",
        "JAX",
        "PyTorch",
        "Installation"
      ],
      "description": "We look at a few State of the Art AI models in weather forecasting, and demonstrate how to run them on AMD Instinct MI300X in a step-by-step fashion.",
      "language": "English",
      "verticals": [
        "AI, Data Science"
      ]
    },
    {
      "slug": "hybrid-models,-mla,",
      "path": "blogs/artificial-intelligence/hybrid-models,-mla,",
      "category": "artificial-intelligence",
      "title": "AMD-HybridLM: Towards Extremely Efficient Hybrid Language Models",
      "date": "17 Sep 2025",
      "author": "Mehdi Rezagholizadeh, Mingyu Yang, Guihong Li, Vikram Appia, Emad Barsoum",
      "thumbnail": "images/meh.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Explore AMD-HybridLM’s architecture and see how hybridization redefines LLM efficiency and performance without requiring retraining from scratch",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "rocm-7.0-blog",
      "path": "blogs/ecosystems-and-partners/rocm-7.0-blog",
      "category": "ecosystems-and-partners",
      "title": "ROCm 7.0: an AI-Ready Powerhouse for Performance, Efficiency, and Productivity",
      "date": "16 Sep 2025",
      "author": "Liam Berry, Mohammed Faraaz Mustafa, Danny Guan, Saad Rahim, Aditya Bhattacharji, Marilyn Basanta ",
      "thumbnail": "images/ROCm-7.0-blog-thumbnail.webp",
      "tags": [
        "AI/ML",
        "Scientific Computing",
        "Compiler",
        "Computer Vision",
        "HPC",
        "JAX",
        "Optimization",
        "Performance",
        "Profiling",
        "PyTorch"
      ],
      "description": "Discover how ROCm 7.0 integrates AI across every layer, combining hardware enablement, frameworks, model support, and a suite of optimized tools",
      "language": "English",
      "verticals": [
        "Developers, HPC, AI, Systems, Data Science"
      ]
    },
    {
      "slug": "mtp",
      "path": "blogs/software-tools-optimization/mtp",
      "category": "software-tools-optimization",
      "title": "Efficient LLM Serving with MTP: DeepSeek V3 and SGLang on AMD Instinct GPUs",
      "date": "11 Sep 2025",
      "author": "Chang Liu, Andy Luo, Anshul Gupta",
      "thumbnail": "images/SGLang.webp",
      "tags": [
        "AI/ML",
        "Performance",
        "Serving"
      ],
      "description": "This blog will show you how to speed up LLM inference with Multi-Token Prediction in DeepSeek V3 & SGLang on AMD Instinct GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "rocm-ray",
      "path": "blogs/artificial-intelligence/rocm-ray",
      "category": "artificial-intelligence",
      "title": "Exploring Use Cases for Scalable AI: Implementing Ray with ROCm Support for Efficient ML Workflows",
      "date": "10 Sep 2025",
      "author": "Vicky Tsang, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/thumbnail_rocm_ray.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Fine-Tuning",
        "Reinforcement Learning",
        "Serving"
      ],
      "description": "Ray, combined with ROCm, provides a powerful platform for scaling AI applications, particularly for training and inference workloads.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mlperf-inference-v5.1",
      "path": "blogs/artificial-intelligence/mlperf-inference-v5.1",
      "category": "artificial-intelligence",
      "title": "Technical Dive into AMD's MLPerf Inference v5.1 Submission",
      "date": "09 Sep 2025",
      "author": "Meena Arunachalam, Miro Hodak, Poovaiah Palangappa, Wei-Ting Liao, Uma Kannikanti, Fulu Li, Neha Mathews, Rajesh Poornachandran, Ean Garvey, Kumar Deepak, Yixing Xu, Zhe Li, Guanchen Li, Xuanwu Yin, Dong Li, Zhao Lin, Wei Luo, Bowen Bao, Spandan Tiwari, Niels Zhang, Vinayak Gokhale, Clint Greene, Eliot Li",
      "thumbnail": "images/mlperf_inf_v5.1_technical_thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Performance",
        "Optimization",
        "MLPerf Inference",
        "MLPerf"
      ],
      "description": "In this blog, we share the technical details of how we accomplish the results in our MLPerf Inference v5.1 submission.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mlperf-inference5.1-repro",
      "path": "blogs/artificial-intelligence/mlperf-inference5.1-repro",
      "category": "artificial-intelligence",
      "title": "Reproducing the AMD Instinct™ GPUs MLPerf Inference v5.1 Submission",
      "date": "09 Sep 2025",
      "author": "Meena Arunachalam, Miro Hodak, Poovaiah Palangappa, Wei-Ting Liao, Uma Kannikanti, Fulu Li, Karan Verma, Neha Mathews, Yamini Kamisetty, Chelsea Iluno, Ean Garvey, Kumar Deepak, Yixing Xu, Zhe Li, Guanchen Li, Xuanwu Yin, Dong Li, Clint Greene, Eliot Li",
      "thumbnail": "images/mlperf_inf_v5.1_repro_thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Performance",
        "Optimization",
        "MLPerf Inference",
        "MLPerf"
      ],
      "description": "In this blog, we will provide step by step instruction on how to reproduce AMD's MLPerf Inference v5.1 Submission",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mlperf-llama-pruning",
      "path": "blogs/artificial-intelligence/mlperf-llama-pruning",
      "category": "artificial-intelligence",
      "title": "Slim Down Your Llama: Pruning & Fine-Tuning for Maximum Performance",
      "date": "9 Sep 2025",
      "author": "Meena Arunachalam, Miro Hodak, Poovaiah Palangappa, Fulu Li, Yixing Xu, Zhe Li, Guanchen Li, Xuanwu Yin, Dong Li, Karan Verma, Clint Greene, Eliot Li",
      "thumbnail": "images/prune_llama_thumbnail.webp",
      "tags": [
        "Fine-Tuning",
        "AI/ML",
        "GenAI",
        "Optimization",
        "Performance",
        "MLPerf Inference",
        "MLPerf"
      ],
      "description": "This blog describes the technical details of how we prune and fine tune the Llama 3.1 405B model in our MLPerf Inference v5.1 submission.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama-cpp",
      "path": "blogs/ecosystems-and-partners/llama-cpp",
      "category": "ecosystems-and-partners",
      "title": "Llama.cpp Meets Instinct: A New Era of Open-Source AI Acceleration",
      "date": "9 Sep 2025",
      "author": "Deepan Sekar, Pei Zhang, Eliot Li, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/llama_cpp_thumbnail.webp",
      "tags": [
        "AI/ML",
        "C++",
        "Performance",
        "Serving"
      ],
      "description": "performance optimizations for llama.cpp on AMD Instinct GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "hipblaslt-offline-tuning-part1",
      "path": "blogs/software-tools-optimization/hipblaslt-offline-tuning-part1",
      "category": "software-tools-optimization",
      "title": "GEMM Tuning within hipBLASLt- Part 1",
      "date": "05 Sep 2025",
      "author": "YangWen Huang, Carson Liao",
      "thumbnail": "images/hipblaslt_tuning_header.webp",
      "tags": [
        "AI/ML",
        "Developers"
      ],
      "description": "We introduce a hipBLASLt tuning tool that lets developers optimize GEMM problem sizes and integrate them into the library.",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "step3-model",
      "path": "blogs/artificial-intelligence/step3-model",
      "category": "artificial-intelligence",
      "title": "Step-3 Deployment Simplified: A Developer’s Guide on AMD Instinct™ GPUs",
      "date": "4 Sep 2025",
      "author": "George Wang, Ning Zhang",
      "thumbnail": "images/tb21.webp",
      "tags": [
        "AI/ML",
        "Serving"
      ],
      "description": "Learn how to deploy Step-3, a 321B-parameter VLM with MFA & AFD, on AMD Instinct™ GPUs to cut decoding costs and boost long-context reasoning",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "disaggregation",
      "path": "blogs/software-tools-optimization/disaggregation",
      "category": "software-tools-optimization",
      "title": "Prefill Decode Disaggregation on AMD Instinct MI300X SGLang",
      "date": "28 Aug 2025",
      "author": "Bill He,Andy Luo",
      "thumbnail": "images/pd.webp",
      "tags": [
        "AI/ML",
        "Optimization",
        "Performance"
      ],
      "description": "Learn how prefill–decode disaggregation improves LLM inference by reducing latency, enhancing throughput, and optimizing resource usage.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "quick-reduce",
      "path": "blogs/artificial-intelligence/quick-reduce",
      "category": "artificial-intelligence",
      "title": "QuickReduce: Up to 3x Faster All-Reduce for  vLLM and SGLang",
      "date": "26 Aug 2025",
      "author": "Haoyang Li, Wei Luo, Xinjun Niu, Spandan Tiwari, Ke Wang, Jiangyong Ren, Ashish Sirasao, Doug Lehr",
      "thumbnail": "images/quick.webp",
      "tags": [
        "Performance",
        "AI/ML",
        "LLM"
      ],
      "description": "Quick Reduce speeds up LLM inference on AMD Instinct™ MI300X GPUs with inline-compressed all-reduce, cutting comms overhead by up to 3×",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "aiter-mla",
      "path": "blogs/software-tools-optimization/aiter-mla",
      "category": "software-tools-optimization",
      "title": "AITER Enabled MLA layer Inference on AMD Instinct MI300X GPUs",
      "date": "25 Aug 2025",
      "author": "Daniel Huang, George Wang",
      "thumbnail": "images/aiter.webp",
      "tags": [
        "AI/ML",
        "Performance"
      ],
      "description": "AITER boosts DeepSeek-V3’s MLA on AMD MI300X GPUs with low-rank projections, shared KV paths & matrix absorption for 2× faster inference.",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "elvm,-vlms,-llm,",
      "path": "blogs/artificial-intelligence/elvm,-vlms,-llm,",
      "category": "artificial-intelligence",
      "title": "Introducing AMD EVLM: Efficient Vision-Language Models with Parameter-Space Visual Conditioning",
      "date": "22 Aug 2025",
      "author": "Zhenhua Liu, Xuanwu Yin, Dong Li, Emad Barsoum",
      "thumbnail": "images/EVLM_thum.webp",
      "tags": [
        "Multimodal",
        "AI/ML"
      ],
      "description": "A novel approach that replaces visual tokens with perception-conditioned weights, reducing compute while maintaining strong vision-language performance.",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "primus",
      "path": "blogs/software-tools-optimization/primus",
      "category": "software-tools-optimization",
      "title": "Primus: A Lightweight, Unified Training Framework for Large Models on AMD GPUs",
      "date": "22 Aug 2025",
      "author": "Wen Xie ,Yao Fu, Xiaoming Peng, Xiaobo Chen, Liz Li, Vidushi Goyal, Anshul Gupta",
      "thumbnail": "images/primus.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Primus streamlines LLM training on AMD GPUs with unified configs, multi-backend support, preflight validation, and structured logging.",
      "language": "English",
      "verticals": [
        "AI, Developers"
      ]
    },
    {
      "slug": "dgl_blog2",
      "path": "blogs/artificial-intelligence/dgl_blog2",
      "category": "artificial-intelligence",
      "title": "DGL in the Real World: Running GNNs on Real Use Cases",
      "date": "20 Aug 2025",
      "author": "Mukhil Azhagan Mallaiyan Sathiaseelan, Anuya Welling, James E. T. Smith, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/thumbnail_dgl2.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "We walk through four advanced GNN workloads from heterogeneous e-commerce graphs to neuroscience applications that we successfully ran using our DGL implementation.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "fastvideo-v1",
      "path": "blogs/artificial-intelligence/fastvideo-v1",
      "category": "artificial-intelligence",
      "title": "Accelerating FastVideo on AMD GPUs with TeaCache",
      "date": "19 Aug 2025",
      "author": "Sopiko Kurdadze",
      "thumbnail": "images/panda_thumbnail.webp",
      "tags": [
        "AI/ML",
        "Diffusion Model",
        "GenAI"
      ],
      "description": "Enabling ROCm support for FastVideo inference using TeaCache on AMD Instinct GPUs, accelerating video generation with optimized backends",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "finetuning-wan-part1",
      "path": "blogs/artificial-intelligence/finetuning-wan-part1",
      "category": "artificial-intelligence",
      "title": "Wan2.2 Fine-Tuning: Tailoring an Advanced Video Generation Model on a Single GPU",
      "date": "Aug 19 2025",
      "author": "Arttu Niemela, Balazs Toth",
      "thumbnail": "images/giraffe_thumbnail.webp",
      "tags": [
        "Fine-Tuning",
        "AI/ML",
        "GenAI"
      ],
      "description": "Fine-tune Wan2.2 for video generation on a single AMD Instinct MI300X GPU with ROCm and DiffSynth.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "video-editing-models",
      "path": "blogs/artificial-intelligence/video-editing-models",
      "category": "artificial-intelligence",
      "title": "All-in-One Video Editing with VACE on AMD Instinct GPUs",
      "date": "Aug 19 2025",
      "author": "Johanna Yang, Kristoffer Peyron",
      "thumbnail": "images/cat_thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Diffusion Model"
      ],
      "description": "This blog showcases AMD hardware powering cutting-edge text-driven video editing models through an all-in-one solution.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "comfyui-on-amd",
      "path": "blogs/software-tools-optimization/comfyui-on-amd",
      "category": "software-tools-optimization",
      "title": "Running ComfyUI on AMD Instinct",
      "date": "19 Aug 2025",
      "author": "Albin Toft",
      "thumbnail": "images/comfyui-on-amd-thumbnail.webp",
      "tags": [
        "AI/ML",
        "Serving",
        "Diffusion Model",
        "GenAI"
      ],
      "description": "This blog shows how to deploy ComfyUI on AMD Instinct GPUs. The blog explains what ComfyUI is and how it works.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "profiling-guide/novice",
      "path": "blogs/software-tools-optimization/profiling-guide/novice",
      "category": "software-tools-optimization",
      "title": "AMD GPU profiling guide - Basic Usage",
      "date": "13 August 2025",
      "author": "Gina Sitaraman, Thomas Gibson, Luka Stanisic, Giacomo Capodaglio, Alessandro Fanfarillo, Asitav Mishra",
      "thumbnail": "2025-06-25-profiling-guide.png",
      "tags": [
        "HPC",
        "Performance",
        "Optimization",
        "Profiling"
      ],
      "description": "Part 2 of our GPU profiling series guides beginners through practical steps to identify and optimize kernel bottlenecks using ROCm tools",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "instella-math-language",
      "path": "blogs/artificial-intelligence/instella-math-language",
      "category": "artificial-intelligence",
      "title": "Introducing Instella-Math: Fully Open Language Model with Reasoning Capability",
      "date": "9 Aug 2025",
      "author": "Xiaodong Yu, Jiang Liu, Yusheng Su, Gowtham Ramesh, Zicheng Liu, Prakamya Mishra, Sudhanshu Ranjan, Jialian Wu, Ximeng Sun, Ze Wang, Emad Barsoum",
      "thumbnail": "images/instella-math-thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Instella-Math is AMD’s 3B reasoning model, trained on 32 MI300X GPUs with open weights, optimized for logic, math, and chain-of-thought tasks.",
      "language": "English",
      "verticals": [
        "AI, Developers"
      ]
    },
    {
      "slug": "rocm-on-wsl",
      "path": "blogs/software-tools-optimization/rocm-on-wsl",
      "category": "software-tools-optimization",
      "title": "Running ComfyUI in Windows with ROCm on WSL",
      "date": "07 Aug 2025",
      "author": "Warren Eng",
      "thumbnail": "images/ROCm_On_WSL_Blog_Thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Run ComfyUI on Windows with ROCm and WSL to harness Radeon GPU power for local AI tasks like Stable Diffusion—no dual-boot needed",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "openai-day-0",
      "path": "blogs/ecosystems-and-partners/openai-day-0",
      "category": "ecosystems-and-partners",
      "title": "Day 0 Developer Guide: Running the First Open GPT Models from OpenAI on AMD AI Hardware",
      "date": "05 Aug 2025",
      "author": "Andy Luo, Shekhar Pandey, Hongxia Yang, Mahdi Ghodsi, Charles Yang, Niles Burbank, George Wang, Kailash Gogineni,Xun Wang, Zhenyu Gu, Yao Fu, Yanyuan Qin, Anshul Gupta",
      "thumbnail": "images/NEWIMAGE.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Day 0 support across our AI hardware ecosystem from our flagship AMD InstinctTM MI355X and MI300X GPUs, AMD Radeon™ AI PRO R700 GPUs and AMD Ryzen™ AI Processors",
      "language": "English",
      "verticals": [
        "Developers, AI, Data Science"
      ]
    },
    {
      "slug": "image-to-video",
      "path": "blogs/artificial-intelligence/image-to-video",
      "category": "artificial-intelligence",
      "title": "AMD Hummingbird Image to Video: A Lightweight Feedback-Driven Model for Efficient Image-to-Video Generation",
      "date": "3 Aug 2025",
      "author": "Takashi Isobe, Dong zhou, He Cui,Mengmeng Ge,Dong Li,Emad Barsoum",
      "thumbnail": "images/hummingbird.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "We present AMD Hummingbird, offering a two-stage distillation framework for efficient, high-quality text-to-video generation using compact models.",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "triton-kernel-ai",
      "path": "blogs/software-tools-optimization/triton-kernel-ai",
      "category": "software-tools-optimization",
      "title": "GEAK: Introducing Triton Kernel AI Agent & Evaluation Benchmark",
      "date": "01 Aug 2025",
      "author": "Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Chao Xu, Bin Ding, Ziqiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, Emad Barsoum",
      "thumbnail": "images/1.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "AMD introduces GEAK, an AI agent for generating optimized Triton GPU kernels, achieving up to 63% accuracy and up to 2.59× speedups on MI300X GPUs.",
      "language": "English",
      "verticals": [
        "Developers, AI"
      ]
    },
    {
      "slug": "taichi",
      "path": "blogs/artificial-intelligence/taichi",
      "category": "artificial-intelligence",
      "title": "Accelerating Parallel Programming in Python with Taichi Lang on AMD GPUs",
      "date": "31 Jul 2025",
      "author": "Tiffany Mintz, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/taichi_blog_thumbnail.webp",
      "tags": [
        "AI/ML",
        "Scientific Computing"
      ],
      "description": "This blog provides a how-to guide on installing and programming with Taichi Lang on AMD Instinct GPUs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "why-graph-neural",
      "path": "blogs/artificial-intelligence/why-graph-neural",
      "category": "artificial-intelligence",
      "title": "Graph Neural Networks at Scale: DGL with ROCm on AMD Hardware",
      "date": "31 Jul 2025",
      "author": "Mukhil Azhagan Mallaiyan Sathiaseelan, Anuya Welling, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "images/dgl_thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Accelerate Graph Deep Learning on AMD GPUs with DGL and ROCm—scale efficiently with open tools and optimized performance.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "lds-bank-conflict",
      "path": "blogs/software-tools-optimization/lds-bank-conflict",
      "category": "software-tools-optimization",
      "title": "Avoiding LDS Bank Conflicts on AMD GPUs with CK-Tile",
      "date": "25 Jul 2025",
      "author": "Haocong Wang, Clement Lin, Meng-Hsuan Yang, Yu-Chen Lin, Bobo Fang, Chun-Hung Wang, David Li, George Wang, Anshul Gupta",
      "thumbnail": "images/12.webp",
      "tags": [
        "Optimization"
      ],
      "description": "This blog shows how CK-Tile’s XOR-based swizzle optimizes shared memory access in GEMM kernels on AMD GPUs by eliminating LDS bank conflicts",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "benchmark-reasoning-models",
      "path": "blogs/artificial-intelligence/benchmark-reasoning-models",
      "category": "artificial-intelligence",
      "title": "Benchmarking Reasoning Models: From Tokens to Answers",
      "date": "24 July 2025",
      "author": "Dominic Widdows",
      "thumbnail": "benchmark_reasoning.png",
      "tags": [
        "AI/ML",
        "Performance",
        "Serving",
        "GenAI",
        "Reasoning",
        "Benchmarking",
        "Thinking Mode"
      ],
      "description": "Learn how to benchmark reasoning tasks. Use Qwen3 and vLLM to test true reasoning performance, not just how fast words are generated.",
      "language": "English",
      "verticals": [
        "AI, Data Science"
      ]
    },
    {
      "slug": "fine-tune-llama3.2",
      "path": "blogs/software-tools-optimization/fine-tune-llama3.2",
      "category": "software-tools-optimization",
      "title": "Chain-of-Thought Guided Visual Reasoning Using Llama 3.2 on a Single AMD Instinct MI300X GPU",
      "date": "21 Jul 2025",
      "author": "Matthias Reso",
      "thumbnail": "images/t.webp",
      "tags": [
        "Fine-Tuning"
      ],
      "description": "Fine-tune Llama 3.2 Vision models on AMD MI300X GPU using Torchtune, achieving 2.3× better accuracy with 11B vs 90B model on chart-based tasks.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "hipcim-intro",
      "path": "blogs/software-tools-optimization/hipcim-intro",
      "category": "software-tools-optimization",
      "title": "Announcing hipCIM: A Cutting-Edge Solution for Accelerated Multidimensional Image Processing",
      "date": "18 July 2025",
      "author": "Soumitra Chatterjee, Karthik Kashyap Thatipamula, Deeksha Goplani, Ish Kool, Anik Chaudhuri, Vikas C Sajjan, Marco Grond",
      "thumbnail": "2025-06-30-hipcim.jpg",
      "tags": [
        "AI/ML",
        "Computer Vision"
      ],
      "description": "Fully utilize the power of AMDs Instinct GPUs to process and interpret detailed multidimensional images with lightning speed.",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "rocm-ls-intro",
      "path": "blogs/software-tools-optimization/rocm-ls-intro",
      "category": "software-tools-optimization",
      "title": "Introducing ROCm-LS: Accelerating Life Science Workloads with AMD Instinct™ GPUs",
      "date": "18 July 2025",
      "author": "Soumitra Chatterjee, Karthik Kashyap Thatipamula, Deeksha Goplani, Ish Kool, Anik Chaudhuri, Vikas C Sajjan, Marco Grond",
      "thumbnail": "2025-06-30-rocm-ls.jpg",
      "tags": [
        "AI/ML"
      ],
      "description": "Accelerate life science and medical workloads with ROCm-LS, AMDs GPU-optimized toolkit for faster multidimensional image processing and vision.",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "vibe-coding-with",
      "path": "blogs/artificial-intelligence/vibe-coding-with",
      "category": "artificial-intelligence",
      "title": "Vibe Coding Pac-Man Inspired Game Generation with DeepSeek-R1 and AMD Instinct MI300X",
      "date": "17 Jul 2025",
      "author": "Charles Yang, Mahdi Ghodsi, George Wang",
      "thumbnail": "images/pac.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM"
      ],
      "description": "Learn LLM-powered game dev using DeepSeek-R1 on AMD MI300X GPUs with iterative prompting, procedural generation, and VS Code AI tools",
      "language": "English",
      "verticals": [
        "Developers"
      ]
    },
    {
      "slug": "instella-t2i",
      "path": "blogs/artificial-intelligence/instella-t2i",
      "category": "artificial-intelligence",
      "title": "Instella-T2I: Open-Source Text-to-Image with 1D Tokenizer and 32× Token Reduction on AMD GPUs",
      "date": "15 Jul 2025",
      "author": "Ze Wang, Hao Chen, Benran Hu, Jiang Liu, Ximeng Sun, Jialian Wu, Xiaodong Yu, Yusheng Su, Zicheng Liu, Emad Barsoum",
      "thumbnail": "images/Figure1.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Explore Instella-T2I: AMD’s open-source text-to-image model, built on MI300X GPUs with novel tokenizer and LLM-based encoder for scalable image generation.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "rocm-lerobot",
      "path": "blogs/artificial-intelligence/rocm-lerobot",
      "category": "artificial-intelligence",
      "title": "Fine-tuning Robotics Vision Language Action Models with AMD ROCm and LeRobot",
      "date": "14 July 2025",
      "author": "Abby O'Neill, Sarunas Kalade, Ken O'Brien, Graham Schelle",
      "thumbnail": "images/thumbnail.webp",
      "tags": [
        "AI/ML",
        "Robotics"
      ],
      "description": "Speed up robotics AI with AMD ROCm and LeRobot: fine-tune VLAs on Instinct GPUs and deploy on Ryzen AI. Follow the tutorial to get started.",
      "language": "English",
      "verticals": [
        "AI, Developers, Robotics"
      ]
    },
    {
      "slug": "video-generation-models",
      "path": "blogs/artificial-intelligence/video-generation-models",
      "category": "artificial-intelligence",
      "title": "Accelerating Video Generation on ROCm with Unified Sequence Parallelism: A Practical Guide",
      "date": "11 July 2025",
      "author": "Clint Greene",
      "thumbnail": "images/video-model-thumbnail.webp",
      "tags": [
        "GenAI"
      ],
      "description": "A practical guide for accelerating video generation with HunyuanVideo and Wan 2.1 using Unified Sequence Parallelism on AMD GPUs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "nitro-t-diffusion",
      "path": "blogs/artificial-intelligence/nitro-t-diffusion",
      "category": "artificial-intelligence",
      "title": "Nitro-T: Training a Text-to-Image Diffusion Model from Scratch in 1 Day",
      "date": "09 July 2025",
      "author": "Akash Haridas, Tong Shen, Jingai Yu",
      "thumbnail": "images/image_row_4x1.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Nitro-T is a family of text-to-image diffusion models developed by AMD to demonstrate efficient large-scale training on Instinct™ MI300X GPUs. Trained from scratch in under 24 hours",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vllmv1-rocm-llm",
      "path": "blogs/software-tools-optimization/vllmv1-rocm-llm",
      "category": "software-tools-optimization",
      "title": "vLLM v1 Meets AMD Instinct: A New Era for LLM Inference Performance",
      "date": "7 Jul 2025",
      "author": "Seungrok Jung, Hyukjoon Lee, Andy Luo",
      "thumbnail": "images/vllmv1-rocm-llm.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "vLLM v1 on AMD ROCm boosts LLM serving with faster TTFT, higher throughput, and optimized multimodal support—ready out of the box.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "amd-container-toolkit",
      "path": "blogs/software-tools-optimization/amd-container-toolkit",
      "category": "software-tools-optimization",
      "title": "Unlocking GPU-Accelerated Containers with the AMD Container Toolkit",
      "date": "03 July 2025",
      "author": "Abhishek Patil",
      "thumbnail": "2025-05-21-container-toolkit.jpg",
      "tags": [
        "Optimization",
        "Performance",
        "AI/ML",
        "Kubernetes"
      ],
      "description": "Simplify GPU acceleration in containers with the AMD Container Toolkit—streamlined setup, runtime hooks, and full ROCm integration.",
      "language": "English",
      "verticals": [
        "AI, Developers, HPC, Data Science, Systems"
      ]
    },
    {
      "slug": "vllm-0.9.x-rocm",
      "path": "blogs/software-tools-optimization/vllm-0.9.x-rocm",
      "category": "software-tools-optimization",
      "title": "Accelerated LLM Inference on AMD Instinct™ GPUs with vLLM 0.9.x and ROCm",
      "date": "28 Jun 2025",
      "author": "Hongxia Yang, Peng Sun, Tun Jian Tan, Pin Siang Tan, Anshul Gupta",
      "thumbnail": "images/tt.webp",
      "tags": [
        "LLM",
        "GenAI",
        "Performance"
      ],
      "description": "vLLM v0.9.x is here with major ROCm™ optimizations—boosting LLM performance, reducing latency, and expanding model support on AMD Instinct™ GPUs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "profiling-guide/intro",
      "path": "blogs/software-tools-optimization/profiling-guide/intro",
      "category": "software-tools-optimization",
      "title": "Performance Profiling on AMD GPUs – Part 1: Foundations",
      "date": "26 June 2025",
      "author": "Gina Sitaraman, Thomas Gibson, Luka Stanisic, Giacomo Capodaglio, Alessandro Fanfarillo, Asitav Mishra",
      "thumbnail": "2025-06-25-profiling-guide.png",
      "tags": [
        "HPC",
        "Performance",
        "Optimization",
        "Profiling"
      ],
      "description": "Part 1 of our GPU profiling series introduces ROCm tools, setup steps, and key concepts to prepare you for deeper dives in the posts to follow.",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "mcp-model-context-protocol",
      "path": "blogs/artificial-intelligence/mcp-model-context-protocol",
      "category": "artificial-intelligence",
      "title": "Enabling Real-Time Context for LLMs: Model Context Protocol (MCP) on AMD GPUs",
      "date": "20 Jun 2025",
      "author": "Fabricio Flores",
      "thumbnail": "images/mcp.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how to leverage Model Context Protocol (MCP) servers to provide real time context information to LLMs through a chatbot example on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "multilingual-continued-pretraining",
      "path": "blogs/artificial-intelligence/multilingual-continued-pretraining",
      "category": "artificial-intelligence",
      "title": "Continued Pretraining: A Practical Playbook for Language-Specific LLM Adaptation",
      "date": "18 Jun 2025",
      "author": "Elaine Zosa, Jouni Luoma, Kai Hakala, Antti Virtanen, Mika Koistinen, Jonathan Burdge",
      "thumbnail": "images/multilingual-continued-pretraining_thumbnail.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "Fine-Tuning"
      ],
      "description": "A step by step guide to adapting LLMs to new languages via continued pretraining, with Poro 2 boosting Finnish performance using Llama 3.1 and AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llm-grpo-rocm",
      "path": "blogs/software-tools-optimization/llm-grpo-rocm",
      "category": "software-tools-optimization",
      "title": "Fine-Tuning LLMs with GRPO on AMD MI300X: Scalable RLHF with Hugging Face TRL and ROCm",
      "date": "18 Jun 2025",
      "author": "Zhu Shan, George Wang",
      "thumbnail": "images/llm-grpo-rocm_thumbnail.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Fine-tune LLMs with GRPO on AMD MI300X—leverage ROCm, Hugging Face TRL, and vLLM for efficient reasoning and scalable RLHF",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "finetuning-trl-dpo",
      "path": "blogs/artificial-intelligence/finetuning-trl-dpo",
      "category": "artificial-intelligence",
      "title": "Aligning Mixtral 8x7B using DPO on AMD GPUs",
      "date": "12 June 2025",
      "author": "Clint Greene",
      "thumbnail": "images/hf-trl-dpo-blog-thumbnail.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "Fine-Tuning",
        "Reinforcement Learning"
      ],
      "description": "This blog demonstrates how to fine-tune and align Mixtral 8x7B with TRL using DPO and evaluate it on AMD GPUs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "instella-long-context",
      "path": "blogs/artificial-intelligence/instella-long-context",
      "category": "artificial-intelligence",
      "title": "Introducing Instella-Long: A Fully Open Language Model with Long-Context Capability",
      "date": "11 June 2025",
      "author": "Jialian Wu, Jiang Liu, Sudhanshu Ranjan, Xiaodong Yu, Gowtham Ramesh, Prakamya Mishra, Zicheng Liu, Yusheng Su, Ximeng Sun, Ze Wang, Emad Barsoum",
      "thumbnail": "images/Image_Instella_Long_Context.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn about Instella-Long: AMD’s open 3B language model supporting 128K context, trained on MI300X GPUs, outperforming peers on long-context benchmarks.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "rocm-revisited-power",
      "path": "blogs/ecosystems-and-partners/rocm-revisited-power",
      "category": "ecosystems-and-partners",
      "title": "AMD ROCm: Powering the World's Fastest Supercomputers",
      "date": "Jun 10 2025",
      "author": "Mohammed Faraaz Mustafa, Saad Rahim",
      "thumbnail": "images/supercomputing.webp",
      "tags": [
        "AI/ML",
        "Scientific Computing",
        "HPC",
        "Performance"
      ],
      "description": "Discover how ROCm drives the world’s top supercomputers, from El Capitan to Frontier, and why its shaping the future of scalable, open and sustainable HPC",
      "language": "English",
      "verticals": [
        "HPC",
        "AI"
      ]
    },
    {
      "slug": "quark",
      "path": "blogs/artificial-intelligence/quark",
      "category": "artificial-intelligence",
      "title": "LLM Quantization with Quark on AMD GPUs: Accuracy and Performance Evaluation",
      "date": "09 June 2025",
      "author": "Sean Song",
      "thumbnail": "quark_LLM.png",
      "tags": [
        "LLM",
        "GenAI",
        "Performance"
      ],
      "description": "Learn how to use Quark to apply FP8 quantization to LLMs on AMD GPUs, and evaluate accuracy and performance using vLLM and SGLang on AMD MI300X GPUs.",
      "language": "English",
      "verticals": [
        "AI",
        "HPC"
      ]
    },
    {
      "slug": "rocm-revisited",
      "path": "blogs/ecosystems-and-partners/rocm-revisited",
      "category": "ecosystems-and-partners",
      "title": "The ROCm Revisited Series",
      "date": "6 Jun 2025",
      "author": "Mohammed Faraaz Mustafa, Liam Berry, Saad Rahim",
      "thumbnail": "images/navigationblog.webp",
      "tags": [
        "Performance",
        "HPC",
        "AI/ML",
        "Optimization"
      ],
      "description": "We present our ROCm Revisited Series. Discover ROCm's role in leading edge supercomputing, its growing ecosystem-from HIP, to developer tools-powering AI, HPC, and data science across multi-GPU and cluster systems",
      "language": "English",
      "verticals": [
        "HPC",
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "rocm-revisited-ecosy",
      "path": "blogs/ecosystems-and-partners/rocm-revisited-ecosy",
      "category": "ecosystems-and-partners",
      "title": "ROCm Revisited: AMD's GPU Computing Ecosystem",
      "date": "6 Jun 2025",
      "author": "Liam Berry, Saad Rahim",
      "thumbnail": "images/rocm-revisited-ecosy.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Kubernetes",
        "Compiler",
        "Developers",
        "Systems"
      ],
      "description": "Learn how ROCm evolved to support HPC, AI, and containerized workloads with modern tools, libraries, and deployment options.",
      "language": "English",
      "verticals": [
        "Developers",
        "AI",
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "rocm-revisited-hip",
      "path": "blogs/ecosystems-and-partners/rocm-revisited-hip",
      "category": "ecosystems-and-partners",
      "title": "ROCm Revisited: Getting Started with HIP",
      "date": "6 Jun 2025",
      "author": "Liam Berry, Mohammed Faraaz Mustafa, Saad Rahim",
      "thumbnail": "images/rocm-revisited-hip.webp",
      "tags": [
        "HPC",
        "Installation",
        "C++"
      ],
      "description": "New to HIP? This blog will introduce you to the HIP runtime API, its key concepts and installation and practical code examples to showcase its functionality.",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems",
        "Developers"
      ]
    },
    {
      "slug": "mlperf-training-v5.0",
      "path": "blogs/artificial-intelligence/mlperf-training-v5.0",
      "category": "artificial-intelligence",
      "title": "AMD’s MLPerf Training Debut: Optimizing LLM Fine-Tuning with Instinct™ GPUs",
      "date": "4 Jun 2025",
      "author": "Meena Arunachalam, Miro Hodak, Ravi Dwivedula, Sarthak Arora, Sathish Sanjeevi, Su Ann Chong, Karan Verma, Eliot Li",
      "thumbnail": "images/MLPerf-Training-v5.0-submission.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Optimization",
        "Performance",
        "LLM"
      ],
      "description": "Explore the techniques we used to improve the training performance on MI300X and MI325X in our MLPerf Training 5.0 submission.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science",
        "HPC"
      ]
    },
    {
      "slug": "reproduce-mlperf-training-v5.0",
      "path": "blogs/artificial-intelligence/reproduce-mlperf-training-v5.0",
      "category": "artificial-intelligence",
      "title": "Reproduce the MLPerf Training v5.0 Submission Result By AMD Using the Instinct™ GPUs",
      "date": "4 Jun 2025",
      "author": "Meena Arunachalam, Miro Hodak, Ravi Dwivedula, Su Ann Chong, Sarthak Arora, Sathish Sanjeevi, Karan Verma, Eliot Li",
      "thumbnail": "images/MLPerf-Training-v5.0-reproduce.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "Performance",
        "Optimization"
      ],
      "description": "Follow this step-by-step guide to reproduce AMDs MLPerf 5.0 Training Submission with Instinct GPUs using ROCm",
      "language": "English",
      "verticals": [
        "AI",
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "bert-training",
      "path": "blogs/artificial-intelligence/bert-training",
      "category": "artificial-intelligence",
      "title": "High-Throughput BERT-L Pre-Training on AMD Instinct™ GPUs: A Practical Guide",
      "date": "3 June 2025",
      "author": "Meena Arunachalam, Miro Hodak, Ravi Dwivedula, Su Ann Chong, Sarthak Arora, Sathish Sanjeevi, Karan Verma, Eliot Li",
      "thumbnail": "images/BERT-training-blog-thumbnail.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM"
      ],
      "description": "Learn how to optimize BERT-L training with mixed precision and Flash Attention v2 on AMD Instinct GPUs — follow our tested MLPerf-compliant step-by-step guide.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "multinode-inference",
      "path": "blogs/artificial-intelligence/multinode-inference",
      "category": "artificial-intelligence",
      "title": "Scale LLM Inference with Multi-Node Infrastructure",
      "date": "30 May 2025",
      "author": "Jorge Parada, Eliot Li",
      "thumbnail": "images/scale-inference-thumbnail.webp",
      "tags": [
        "AI/ML",
        "Serving",
        "LLM"
      ],
      "description": "Learn how to horizontally scale LLM inference using open-source tools on MI300X, with  vLLM, nginx, Prometheus, and Grafana.",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "transition-to-hip-7.0-blog",
      "path": "blogs/ecosystems-and-partners/transition-to-hip-7.0-blog",
      "category": "ecosystems-and-partners",
      "title": "HIP 7.0 Is Coming: What You Need to Know to Stay Ahead",
      "date": "28 May 2025",
      "author": "Christophe Paquot, Julia Jiang, Denny Iriawan, Saad Rahim",
      "thumbnail": "hip-runtime-7.jpg",
      "tags": [
        "Compiler",
        "Developers",
        "HPC"
      ],
      "description": "Get ready for HIP 7.0—explore key API changes that boost CUDA compatibility and streamline portable GPU development, start preparing your code today.",
      "language": "English",
      "verticals": [
        "Developers",
        "HPC"
      ]
    },
    {
      "slug": "amd-rocm-runfile",
      "path": "blogs/software-tools-optimization/amd-rocm-runfile",
      "category": "software-tools-optimization",
      "title": "ROCm Runfile Installer Is Here!",
      "date": "22 May 2025",
      "author": "Douglas Hamilton, Saad Rahim, Liam Berry",
      "thumbnail": "images/runfile-installer.webp",
      "tags": [
        "Installation",
        "Developers",
        "Systems"
      ],
      "description": "Overview of ROCm Runfile Installer introduced in ROCm 6.4, allowing a complete single package for driver and ROCm installation without internet connectivity",
      "language": "English",
      "verticals": [
        "Systems",
        "Developers"
      ]
    },
    {
      "slug": "ck-tile-flash",
      "path": "blogs/software-tools-optimization/ck-tile-flash",
      "category": "software-tools-optimization",
      "title": "From Theory to Kernel: Implement FlashAttention-v2 with CK-Tile",
      "date": "21 May 2025",
      "author": "Haocong Wang, Kevin Chang, David Li, George Wang",
      "thumbnail": "images/CK.webp",
      "tags": [
        "AI/ML",
        "Developers"
      ],
      "description": "Learn how to implement FlashAttention-v2 with CK-Tile: minimize memory overhead, maximize compute efficiency, and scale on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "llm-d-distributed",
      "path": "blogs/artificial-intelligence/llm-d-distributed",
      "category": "artificial-intelligence",
      "title": "AMD Integrates llm-d on AMD Instinct MI300X Cluster For Distributed LLM Serving",
      "date": "20 May 2025",
      "author": "Kenny Roche, Joe Shajrawi, Andy Luo, Anshul Gupta",
      "thumbnail": "images/LLLMD.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "AMD Integrates llm-d on AMD Instinct MI300X Cluster For Distributed LLM Serving",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "introducing-rocm-ds-revolutionizing-data-processing-with-amd-instinct-gpus",
      "path": "blogs/software-tools-optimization/introducing-rocm-ds-revolutionizing-data-processing-with-amd-instinct-gpus",
      "category": "software-tools-optimization",
      "title": "Introducing ROCm-DS: GPU-Accelerated Data Science for AMD Instinct™ GPUs",
      "date": "20 May 2025",
      "author": "Marco Grond, Saad Rahim",
      "thumbnail": "2025-04-21-ROCm-DS.jpg",
      "tags": [
        "Scientific Computing",
        "Developers",
        "HPC"
      ],
      "description": "Accelerate data science with ROCm-DS: AMD’s GPU-optimized toolkit for faster data frames and graph analytics using hipDF and hipGRAPH",
      "language": "English",
      "verticals": [
        "HPC",
        "Developers"
      ]
    },
    {
      "slug": "aiter-intergration-s",
      "path": "blogs/artificial-intelligence/aiter-intergration-s",
      "category": "artificial-intelligence",
      "title": "Accelerate DeepSeek-R1 Inference: Integrate AITER into SGLang",
      "date": "16 May 2025",
      "author": "Bruce Xue, George Wang",
      "thumbnail": "images/Thumbn.webp",
      "tags": [
        "Optimization"
      ],
      "description": "Boost DeepSeek-R1 with AITER: Step-by-step SGLang integration for high-performance MoE, GEMM, and attention ops on AMD GPUs",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "step-video-t2v",
      "path": "blogs/artificial-intelligence/step-video-t2v",
      "category": "artificial-intelligence",
      "title": "Step-Video-T2V Inference with xDiT on AMD Instinct  MI300X GPUs",
      "date": "15 May 2025",
      "author": "Wei Cai, George Wang",
      "thumbnail": "images/thumb.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how to accelerate text-to-video generation using Step-Video-T2V, a 30B parameter T2V model, on AMD MI300X GPUs with ROCm—enabling scalable, high-fidelity video generation from text",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "rocjpeg-decoding-performance-blog",
      "path": "blogs/artificial-intelligence/rocjpeg-decoding-performance-blog",
      "category": "artificial-intelligence",
      "title": "Accelerated JPEG decoding on AMD Instinct™ GPUs with rocJPEG",
      "date": "12 May 2025",
      "author": "Marco Grond",
      "thumbnail": "2025-04-10-rocJPEG.png",
      "tags": [
        "Computer Vision"
      ],
      "description": "Learn how to decompress JPEG files at breakneck speeds for your AI, vision, and content delivery workloads using rocJPEG and AMD Instinct GPUs.",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "hipDF_pandas_accelerated",
      "path": "blogs/artificial-intelligence/hipDF_pandas_accelerated",
      "category": "artificial-intelligence",
      "title": "DataFrame Acceleration: hipDF and hipDF.pandas on AMD GPUs.",
      "date": "7 May 2025",
      "author": "Fabricio Flores",
      "thumbnail": "hipDF_Dataframe.jpeg",
      "tags": [
        "PyTorch",
        "AI/ML"
      ],
      "description": "This blog post demonstrates how hipDF significantly enhances and accelerates data manipulation, aggregation, and transformation tasks on AMD hardware using ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "cupy_hipdf_portfolio_opt",
      "path": "blogs/artificial-intelligence/cupy_hipdf_portfolio_opt",
      "category": "artificial-intelligence",
      "title": "CuPy and hipDF on AMD: The Basics and Beyond",
      "date": "6 May 2025",
      "author": "Fabricio Flores",
      "thumbnail": "cupy_hipdf.jpeg",
      "tags": [
        "PyTorch",
        "AI/ML"
      ],
      "description": "Learn how to deploy CuPy and hipDF on AMD GPUs. See their high-performance computing advantages, and use CuPy and hipDF in a detailed example of an investment portfolio allocation optimization using the Markowitz model.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "triton-distributed-c",
      "path": "blogs/software-tools-optimization/triton-distributed-c",
      "category": "software-tools-optimization",
      "title": "Unleash Full GPU Potential: Overlap Communication and Computation with Triton-Distributed",
      "date": "06 May 2025",
      "author": "Lei Zhang, George Wang, Fan Wu, Peng Sun, Kyle Wang, Anshul Gupta",
      "thumbnail": "images/BD.webp",
      "tags": [
        "Compiler"
      ],
      "description": "Unlock the full power of AMD GPUs—write portable, efficient kernels with Triton-Distributed, overlapping computation and communication with ease and flexibility",
      "language": "English",
      "verticals": [
        "Developers"
      ]
    },
    {
      "slug": "kernel-analysis-deep",
      "path": "blogs/software-tools-optimization/kernel-analysis-deep",
      "category": "software-tools-optimization",
      "title": "Optimizing DeepseekV3 Inference on SGLang Using ROCm Profiling Tools",
      "date": "1 May 2025",
      "author": "Liz Li, Shekhar Pandey, Seungrok Jung, Andy Luo",
      "thumbnail": "images/Whale.webp",
      "tags": [
        "Optimization"
      ],
      "description": "Dive into kernel-level profiling of DeepseekV3 on SGLang—identify GPU bottlenecks and boost large language model performance using ROCm",
      "language": "English",
      "verticals": [
        "Data Science"
      ]
    },
    {
      "slug": "qwen3-day0-amd",
      "path": "blogs/artificial-intelligence/qwen3-day0-amd",
      "category": "artificial-intelligence",
      "title": "Power Up Qwen 3 with AMD Instinct: A Developer’s Day 0 Quickstart",
      "date": "28 Apr 2025",
      "author": "Andy Luo, Bill He, Seungrok Jung, Mahdi Ghodsi",
      "thumbnail": "qwen.jpg",
      "tags": [
        "AI/ML"
      ],
      "description": "Explore the power of Alibaba's QWEN3 models on AMD Instinct™ MI300X and MI325X GPUs - available from Day 0 with seamless SGLang and vLLM integration",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama4-performance-b",
      "path": "blogs/software-tools-optimization/llama4-performance-b",
      "category": "software-tools-optimization",
      "title": "Boosting Llama 4 Inference Performance with AMD Instinct MI300X GPUs",
      "date": "28 Apr 2025",
      "author": "Liz Li, Seungrok Jung, Andy Luo, Shekhar Pandey",
      "thumbnail": "images/Llama_thumb.webp",
      "tags": [
        "LLM"
      ],
      "description": "Learn how to boost your Llama 4 inference performance on AMD MI300X GPUs using AITER-optimized kernels and advanced vLLM techniques",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "multimodal-spec-dec",
      "path": "blogs/software-tools-optimization/multimodal-spec-dec",
      "category": "software-tools-optimization",
      "title": "Beyond Text: Accelerating Multimodal AI Inference with Speculative Decoding on AMD Instinct™ MI300X GPUs",
      "date": "28 Apr 2025",
      "author": "Mohammad Mahdi Kamani, Parsa Fashi, Vikram Appia, Emad Barsoum",
      "thumbnail": "thumb.jpg",
      "tags": [
        "AI/ML"
      ],
      "description": "This blog shows you how to speedup your multimodal models with AMD’s open-source PyTorch tools for speculative decoding on MI300X GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "verl-large-scale",
      "path": "blogs/artificial-intelligence/verl-large-scale",
      "category": "artificial-intelligence",
      "title": "Reinforcement Learning from Human Feedback on AMD GPUs with verl and ROCm Integration",
      "date": "24 Apr 2025",
      "author": "Yusheng Su, Vicky Tsang, Yao Liu, Phani Vaddadi, Vish Vadlamani, Zicheng Liu",
      "thumbnail": "images/verl.webp",
      "tags": [
        "Fine-Tuning",
        "Reinforcement Learning",
        "AI/ML"
      ],
      "description": "Deploy verl on AMD GPUs for fast, scalable RLHF training with ROCm optimization, Docker scripts, and impressive throughput-convergence results",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama-stack-on",
      "path": "blogs/ecosystems-and-partners/llama-stack-on",
      "category": "ecosystems-and-partners",
      "title": "A step-by-step guide on how to deploy Llama Stack on AMD Instinct™ GPU",
      "date": "22 Apr 2025",
      "author": "Alex He",
      "thumbnail": "images/3.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how to use Meta’s Llama Stack with AMD ROCm and vLLM to scale inference, integrate APIs, and streamline production-ready AI workflows on AMD Instinct™ GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "building-efficient-gemm-kernels-with-ck-tile-vendo",
      "path": "blogs/software-tools-optimization/building-efficient-gemm-kernels-with-ck-tile-vendo",
      "category": "software-tools-optimization",
      "title": "Hands-On with CK-Tile: Develop and Run Optimized GEMM on AMD GPUs",
      "date": "15 Apr 2025",
      "author": "David Li, George Wang",
      "thumbnail": "2.jpg",
      "tags": [
        "Fine-Tuning"
      ],
      "description": "Build high-performance GEMM kernels using CK-Tile on AMD Instinct GPUs with vendor-optimized pipelines and policies for AI and HPC workloads",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "spack-installation",
      "path": "blogs/software-tools-optimization/spack-installation",
      "category": "software-tools-optimization",
      "title": "Installing ROCm from source with Spack",
      "date": "14 April 2025",
      "author": "Garrett Byrd, Joseph Schoonover",
      "thumbnail": "images/spack-thumbnail.webp",
      "tags": [
        "Scientific Computing",
        "HPC",
        "Installation"
      ],
      "description": "Install ROCm and PyTorch from source using Spack. Learn how to optimize builds, manage dependencies, and streamline your GPU software stacks.",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "instinct-gpu-driver",
      "path": "blogs/ecosystems-and-partners/instinct-gpu-driver",
      "category": "ecosystems-and-partners",
      "title": "ROCm Gets Modular: Meet the Instinct Datacenter GPU Driver",
      "date": "11 Apr 2025",
      "author": "Saad Rahim, Danny Guan",
      "thumbnail": "divergence.png",
      "tags": [
        "Installation"
      ],
      "description": "We introduce the new Instinct driver-a modular GPU driver with independent releases simplifying workflows, system setup, and enhancing compatibility across toolkit versions.",
      "language": "English",
      "verticals": [
        "Systems"
      ]
    },
    {
      "slug": "rocm-6.4-blog",
      "path": "blogs/ecosystems-and-partners/rocm-6.4-blog",
      "category": "ecosystems-and-partners",
      "title": "ROCm 6.4: Breaking Barriers in AI, HPC, and Modular GPU Software",
      "date": "11 Apr 2025",
      "author": "Jayacharan Kolla, Aditya Bhattacharji, Farshad Ghodsian, Saad Rahim, Marco Grond, Ronnie Chatterjee",
      "thumbnail": "images/rocm-6.4-blog.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Computer Vision",
        "Profiling",
        "Kubernetes"
      ],
      "description": "Explore ROCm 6.4's key advancements: AI/HPC performance boosts, enhanced profiling tools, better Kubernetes support and modular drivers, accelerating AI and HPC workloads on AMD GPUs.",
      "language": "English",
      "verticals": [
        "HPC",
        "AI",
        "Data Science",
        "Systems"
      ]
    },
    {
      "slug": "kernel-development-optimizations-with-triton-on-",
      "path": "blogs/software-tools-optimization/kernel-development-optimizations-with-triton-on-",
      "category": "software-tools-optimization",
      "title": "Unlock Peak Performance on AMD GPUs with Triton Kernel Optimizations",
      "date": "10 Apr 2025",
      "author": "Ning Zhang, George Wang",
      "thumbnail": "1.jpg",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how Triton compiles and optimizes AI kernels on AMD GPUs, with deep dives into IR flows, hardware-specific passes, and performance tuning tips",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "gptq",
      "path": "blogs/artificial-intelligence/gptq",
      "category": "artificial-intelligence",
      "title": "Shrink LLMs, Boost Inference: INT4 Quantization on AMD GPUs with GPTQModel",
      "date": "9 April 2025",
      "author": "Fabricio Flores",
      "thumbnail": "images/quantization.webp",
      "tags": [
        "GenAI",
        "AI/ML",
        "Performance",
        "Optimization"
      ],
      "description": "Learn how to compress LLMs with GPTQModel and run them efficiently on AMD GPUs using INT4 quantization, reducing memory use, shrinking model size, and enabling fast inference",
      "language": "English",
      "verticals": [
        "AI",
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "llama4-day-0-support",
      "path": "blogs/artificial-intelligence/llama4-day-0-support",
      "category": "artificial-intelligence",
      "title": "Power Up Llama 4 with AMD Instinct: A Developer’s Day 0 Quickstart",
      "date": "06 Apr 2025",
      "author": "Liz Li, Seungrok Jung, Andy Luo",
      "thumbnail": "llama.jpg",
      "tags": [
        "AI/ML"
      ],
      "description": "Explore the power of Meta’s Llama 4 multimodal models on AMD Instinct™ MI300X and MI325X GPUs - available from Day 0 with seamless vLLM integration",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mi325x-accelerates-mlperf-inference",
      "path": "blogs/artificial-intelligence/mi325x-accelerates-mlperf-inference",
      "category": "artificial-intelligence",
      "title": "AMD Instinct™ MI325X Produces Strong Performance in MLPerf Inference v5.0",
      "date": "2 April 2025",
      "author": "Meena Arunachalam, Miro Hodak, Wei-Ting Liao, Poovaiah Palangappa, Eliot Li, AMD Quark Team, AMD Brevitas Team, and AMD Shark Team",
      "thumbnail": "mlperf_blog_image2.jpeg",
      "tags": [
        "GenAI",
        "AI/ML",
        "LLM",
        "Optimization",
        "Performance"
      ],
      "description": "We showcase MI325X GPU optimizations that power our MLPerf v5.0 results on Llama 2 70B, highlighting performance tuning, quantization, and vLLM advancements.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science",
        "HPC"
      ]
    },
    {
      "slug": "reproducing-amd-mlperf-inference-submission",
      "path": "blogs/artificial-intelligence/reproducing-amd-mlperf-inference-submission",
      "category": "artificial-intelligence",
      "title": "Reproducing AMD Instinct GPUs MLPerf Inference v5.0 Submission",
      "date": "2 April 2025",
      "author": "Meena Arunachalam, Miro Hodak, Wei-Ting Liao, Karan Verma, Ean Garvey, Kumar Deepak, Giuseppe Franco, Eliot Li, AMD Quark team",
      "thumbnail": "mlperf_blog_image1.jpeg",
      "tags": [
        "GenAI",
        "AI/ML",
        "LLM",
        "Performance",
        "Optimization"
      ],
      "description": "A step-by-step guide to reproducing AMD’s MLPerf v5.0 results for Llama 2 70B & SDXL using ROCm on MI325X",
      "language": "English",
      "verticals": [
        "AI",
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "run-flux-with-hf-diffuser-on-mi300",
      "path": "blogs/artificial-intelligence/run-flux-with-hf-diffuser-on-mi300",
      "category": "artificial-intelligence",
      "title": "Bring FLUX to Life on MI300X: Run and Optimize with Hugging Face Diffusers",
      "date": "28 Mar 2025",
      "author": "Liz Li",
      "thumbnail": "flux_blog.png",
      "tags": [
        "AI/ML",
        "GenAI"
      ],
      "description": "The blog will walk you through the FLUX text-to-image diffusion model architecture and show you how to run and optimize it on MI300x.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "gpu-operator-v1.2",
      "path": "blogs/software-tools-optimization/gpu-operator-v1.2",
      "category": "software-tools-optimization",
      "title": "What's New in the AMD GPU Operator v1.2.0 Release",
      "date": "28 Mar 2025",
      "author": "Farshad Ghodsian",
      "thumbnail": "2025-03-28-gpu-operator-v1.2.jpg",
      "tags": [
        "Kubernetes"
      ],
      "description": "This blog highlights the new feature enhancements that were released as part of the AMD GPU Operator v1.2.0 release. New features that enhance the use of AMD Instinct GPUs on Kubernetes including Automated Upgrades, Health Checks and Open-sourcing the codebase.",
      "language": "English",
      "verticals": [
        "Systems"
      ]
    },
    {
      "slug": "spec_decode_mi300x",
      "path": "blogs/artificial-intelligence/spec_decode_mi300x",
      "category": "artificial-intelligence",
      "title": "Accelerating LLM Inference: Up to 3x Speedup on MI300X with Speculative Decoding",
      "date": "27 March 2025",
      "author": "Sonali Singh, Karthik Sangaiah, Shenrun Zhang, Ryan Swann, Ganesh Dasika",
      "thumbnail": "thumbnail2.png",
      "tags": [
        "AI/ML",
        "LLM",
        "GenAI"
      ],
      "description": "This blog demonstrates out-of-the-box performance improvement in LLM inference using speculative decoding on MI300X.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "introducing-roc-profiler-blog",
      "path": "blogs/software-tools-optimization/introducing-roc-profiler-blog",
      "category": "software-tools-optimization",
      "title": "Introducing ROCprofiler SDK - The Latest Toolkit for Performance Profiling.",
      "date": "25 Mar 2025",
      "author": "Jayacharan Kolla, Ammar Elwazir, Gina Sitaraman",
      "thumbnail": "images/profiler.webp",
      "tags": [
        "Profiling",
        "Performance",
        "AI/ML",
        "System-Tuning",
        "HPC"
      ],
      "description": "Discover ROCprofiler SDK – ROCm’s next-generation, unified, scalable, and high-performance profiling toolkit for AI and HPC workloads on AMD GPUs.",
      "language": "English",
      "verticals": [
        "HPC",
        "AI"
      ]
    },
    {
      "slug": "rocprofiler-sdk",
      "path": "blogs/software-tools-optimization/rocprofiler-sdk",
      "category": "software-tools-optimization",
      "title": "Introducing ROCprofiler SDK - The Latest Toolkit for Performance Profiling.",
      "date": "25 Mar 2025",
      "author": "Jayacharan Kolla, Ammar Elwazir, Gina Sitaraman",
      "thumbnail": "images/profiler.webp",
      "tags": [
        "Profiling",
        "Performance",
        "AI/ML",
        "System-Tuning",
        "HPC"
      ],
      "description": "Discover ROCprofiler SDK – ROCm’s next-generation, unified, scalable, and high-performance profiling toolkit for AI and HPC workloads on AMD GPUs.",
      "language": "English",
      "verticals": [
        "HPC",
        "AI"
      ]
    },
    {
      "slug": "speculative-decoding---deep-dive",
      "path": "blogs/software-tools-optimization/speculative-decoding---deep-dive",
      "category": "software-tools-optimization",
      "title": "Speculative Decoding - Deep Dive",
      "date": "24 Mar 2025",
      "author": "Chang Liu",
      "thumbnail": "images/cover.webp",
      "tags": [
        "GenAI",
        "AI/ML",
        "LLM"
      ],
      "description": "This blog shows the performance improvement achieved by applying speculative decoding with Llama models on AMD MI300X GPUs, tested across models, input sizes, and datasets.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "megablocks",
      "path": "blogs/artificial-intelligence/megablocks",
      "category": "artificial-intelligence",
      "title": "Efficient MoE training on AMD ROCm: How-to use MegaBlocks on AMD GPUs",
      "date": "23 March 2025",
      "author": "Fabricio Flores, Rishi Madduri, Yao Liu, Phani Vaddadi, Vish Vadlamani",
      "thumbnail": "megablocks.jpeg",
      "tags": [
        "PyTorch",
        "AI/ML",
        "LLM"
      ],
      "description": "Learn how to use MegaBlocks to pre-train GPT2 Mixture of Experts (MoE) model, helping you scale your deep learning models effectiveness on AMD GPUs using ROCm",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "DeepSeekR1-Part2",
      "path": "blogs/artificial-intelligence/DeepSeekR1-Part2",
      "category": "artificial-intelligence",
      "title": "Supercharge DeepSeek-R1 Inference on AMD Instinct MI300X",
      "date": "21 Mar 2025",
      "author": "Peng Sun, Andy Luo, Seungrok Jung, Liz Li, Hai Xiao",
      "thumbnail": "deep-seek-part2_thumbnail.png",
      "tags": [
        "AI/ML"
      ],
      "description": "Learn how to optimize DeepSeek-R1 on AMD MI300X with SGLang, AITER kernels and hyperparameter tuning for up to 5× throughput and 60% lower latency over Nvidia H200",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "aiter-ai-tensor-engine",
      "path": "blogs/software-tools-optimization/aiter-ai-tensor-engine",
      "category": "software-tools-optimization",
      "title": "AITER: AI Tensor Engine For ROCm",
      "date": "21 Mar 2025",
      "author": "Shekhar Pandey, Liz Li, Carlus Huang, Lingpeng Jin, Anshul Gupta",
      "thumbnail": "aiter_thumbnail.png",
      "tags": [
        "AI/ML"
      ],
      "description": "We introduce AMD's AI Tensor Engine for ROCm (AITER), our centralized high performance AI operators repository, designed to significantly accelerate AI workloads on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "deployingGemma-vllm",
      "path": "blogs/artificial-intelligence/deployingGemma-vllm",
      "category": "artificial-intelligence",
      "title": "Deploying Google’s Gemma 3 Model with vLLM on AMD Instinct MI300X GPUs: A Step-by-Step Guide",
      "date": "14 Mar 2025",
      "author": "Shekhar Pandey, Anshul Gupta",
      "thumbnail": "gemma_blog.png",
      "tags": [
        "AI/ML",
        "LLM",
        "Serving"
      ],
      "description": "AMD is excited to announce the integration of Google’s Gemma 3 models with AMD Instinct™ MI300X GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "tensor-parallelism",
      "path": "blogs/artificial-intelligence/tensor-parallelism",
      "category": "artificial-intelligence",
      "title": "Analyzing the Impact of Tensor Parallelism Configurations on LLM Inference Performance",
      "date": "14 March 2025",
      "author": "Eduardo Alvarez",
      "thumbnail": "images/tp1.webp",
      "tags": [
        "LLM",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "This blog analyzes how tensor parallelism impacts TCO and Scale for LLM deployments in production.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "k8s-orchestration-part3",
      "path": "blogs/artificial-intelligence/k8s-orchestration-part3",
      "category": "artificial-intelligence",
      "title": "AI Inference Orchestration with Kubernetes on Instinct MI300X, Part 3",
      "date": "13 Mar 2025",
      "author": "Victor Robles",
      "thumbnail": "2025-03-13-k8s-orch-pt3.jpg",
      "tags": [
        "AI/ML",
        "Kubernetes",
        "LLM",
        "GenAI"
      ],
      "description": "This blog is part 3 of a series aimed at providing a comprehensive, step-by-step guide for deploying and scaling AI inference workloads with Kubernetes and the AMD GPU Operator on the AMD Instinct platform",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "amd-optimized-rocm-docker-for-distributed-training",
      "path": "blogs/software-tools-optimization/amd-optimized-rocm-docker-for-distributed-training",
      "category": "software-tools-optimization",
      "title": "Optimized ROCm Docker for Distributed AI Training",
      "date": "13 Mar 2025",
      "author": "Yao Fu, Anshul Gupta",
      "thumbnail": "images/docker_img.webp",
      "tags": [
        "PyTorch",
        "LLM",
        "GenAI",
        "AI/ML",
        "Fine-Tuning",
        "Optimization",
        "Performance"
      ],
      "description": "AMD updated Docker images incorporate torchtune finetuning, FP8 support, single node  performance boost, bug fixes & updated benchmarking for stable, efficient distributed training",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science",
        "HPC"
      ]
    },
    {
      "slug": "Instella-BL-1B-VLM",
      "path": "blogs/artificial-intelligence/Instella-BL-1B-VLM",
      "category": "artificial-intelligence",
      "title": "Instella-VL-1B: First AMD Vision Language Model",
      "date": "7 Mar 2025",
      "author": "Ximeng Sun, Aditya Kumar Singh, Gowtham Ramesh, Zicheng Liu, Pratik Prabhanjan Brahma, Ze Wang, Jiang Liu, Jialian Wu, Prakamya Mishra, Xiaodong Yu, Yusheng Su, Sudhanshu Ranjan, Emad Barsoum",
      "thumbnail": "images/instella-bl-1b-vlm.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM",
        "Multimodal"
      ],
      "description": "We introduce Instella-VL-1B, the first AMD vision language model for image understanding trained on MI300X GPUs, outperforming fully open-source models and matching or exceeding many open-weight counterparts in general multimodal benchmarks and OCR-related tasks.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "introducing-instella-3B",
      "path": "blogs/artificial-intelligence/introducing-instella-3B",
      "category": "artificial-intelligence",
      "title": "Introducing Instella: New State-of-the-art Fully Open 3B Language Models",
      "date": "5 Mar 2025",
      "author": "Jiang Liu, Jialian Wu, Xiaodong Yu, Prakamya Mishra, Sudhanshu Ranjan, Zicheng Liu, Chaitanya Manem, Yusheng Su, Pratik Prabhanjan Brahma, Gowtham Ramesh, Ximeng Sun, Ze Wang, Emad Barsoum",
      "thumbnail": "PR677_thumbnail_7-5.JPG",
      "tags": [
        "AI/ML",
        "Fine-Tuning",
        "Hardware"
      ],
      "description": "AMD is excited to announce Instella, a family of fully open state-of-the-art 3-billion-parameter language models (LMs). , In this blog we explain how the Instella models were trained, and how to access them.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mi300x-rccl-xgmi",
      "path": "blogs/software-tools-optimization/mi300x-rccl-xgmi",
      "category": "software-tools-optimization",
      "title": "Understanding RCCL Bandwidth and xGMI Performance on AMD Instinct MI300X",
      "date": "2 March 2025",
      "author": "Jayacharan Kolla, Pedram Alizadeh, Gilbert Lee",
      "thumbnail": "rccl.png",
      "tags": [
        "System-Tuning",
        "Performance",
        "Optimization"
      ],
      "description": "The blog explains the reasons behind RCCL bandwidth limitations and xGMI performance constraints, and provides actionable steps to maximize link efficiency on AMD MI300X",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "measuring-max-achievable-flops-part2",
      "path": "blogs/software-tools-optimization/measuring-max-achievable-flops-part2",
      "category": "software-tools-optimization",
      "title": "Measuring Max-Achievable FLOPs – Part 2",
      "date": "28 Feb 2025",
      "author": "Ben Sander, Evan Masters, Babak Poursartip, Henry Ho",
      "thumbnail": "images/MAF2_Image.webp",
      "tags": [
        "AI/ML",
        "HPC",
        "Optimization",
        "Performance"
      ],
      "description": "AMD measures Max-Achievable FLOPS through controlled benchmarking: real-world data patterns, thermally stable devices, and cold cache testing—revealing how actual performance differs from theoretical peaks.",
      "language": "English",
      "verticals": [
        "HPC",
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "serverless-ai-inference",
      "path": "blogs/artificial-intelligence/serverless-ai-inference",
      "category": "artificial-intelligence",
      "title": "AI Inference with AMD GPUs: A Modern Serverless Approach",
      "date": "25 Feb 2025",
      "author": "Rathnakara Malatesha",
      "thumbnail": "2025-02-25-serverless-ai-inference.jpg",
      "tags": [
        "LLM",
        "AI/ML",
        "Serving",
        "Kubernetes",
        "GenAI"
      ],
      "description": "This blog helps targeted audience in setting up AI inference serverless deployment in a kubernetes cluster with AMD accelerators. Blog aims to provide a comprehensive guide for deploying and scaling AI inference workloads on serverless infrastructre.",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "DeepSeekR1_Perf",
      "path": "blogs/artificial-intelligence/DeepSeekR1_Perf",
      "category": "artificial-intelligence",
      "title": "Unlock DeepSeek-R1 Inference Performance on AMD Instinct™ MI300X GPUs",
      "date": "21 Feb 2025",
      "author": "Andy Luo",
      "thumbnail": "images/whale.webp",
      "tags": [
        "LLM",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "This blog introduces the key performance optimizations made to enable DeepSeek-R1 Inference",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vllm-container",
      "path": "blogs/software-tools-optimization/vllm-container",
      "category": "software-tools-optimization",
      "title": "How to Build a vLLM Container for Inference and Benchmarking",
      "date": "21 Feb 2025",
      "author": "Matt Elliott",
      "thumbnail": "2025-02-20-vllm-container.png",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI"
      ],
      "description": "This post, the second in a series, provides a walkthrough for building a vLLM container that can be used for both inference and benchmarking.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "multinode_accelerate_phi35",
      "path": "blogs/artificial-intelligence/multinode_accelerate_phi35",
      "category": "artificial-intelligence",
      "title": "Fine-tuning Phi-3.5-mini LLM at scale: Harnessing Accelerate and Slurm for multinode training.",
      "date": "19 Feb 2025",
      "author": "Fabricio Flores",
      "thumbnail": "images/multinode_training_thumbnail_AdobeStock_184095331.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "PyTorch"
      ],
      "description": "Fine-tuning Phi-3.5-mini-instruct LLM using multinode distributed training with Hugging Face Accelerate, Slurm, and Docker for scalable efficiency.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "k8s-orchestration-part2",
      "path": "blogs/artificial-intelligence/k8s-orchestration-part2",
      "category": "artificial-intelligence",
      "title": "AI Inference Orchestration with Kubernetes on Instinct MI300X, Part 2",
      "date": "14 Feb 2025",
      "author": "Victor Robles",
      "thumbnail": "2025-02-13-k8s-orch-pt2.jpg",
      "tags": [
        "Kubernetes",
        "LLM",
        "AI/ML",
        "GenAI"
      ],
      "description": "This blog is part 2 of a series aimed at providing a comprehensive, step-by-step guide for deploying and scaling AI inference workloads with Kubernetes and the AMD GPU Operator on the AMD Instinct platform",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "Understanding_Peak_and_Max-Achievable_FLOPS",
      "path": "blogs/software-tools-optimization/Understanding_Peak_and_Max-Achievable_FLOPS",
      "category": "software-tools-optimization",
      "title": "Understanding Peak, Max-Achievable & Delivered FLOPs",
      "date": "14 Feb, 2025",
      "author": "Ben Sander",
      "thumbnail": "images/maf_bg.webp",
      "tags": [
        "AI/ML",
        "Hardware"
      ],
      "description": "Understanding Peak, Max-Achievable & Delivered FLOPs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "Navigating-vLLM-Inference-with-ROCm-and-Kubernetes",
      "path": "blogs/artificial-intelligence/Navigating-vLLM-Inference-with-ROCm-and-Kubernetes",
      "category": "artificial-intelligence",
      "title": "Navigating vLLM Inference with ROCm and Kubernetes",
      "date": "13 Feb 2025",
      "author": "Alex He",
      "thumbnail": "Thumbnail_475.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Quick introduction to Kubernetes (K8s) and a step-by-step guide on how to use K8s to deploy vLLM using ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "fsdp-training-pytorch",
      "path": "blogs/artificial-intelligence/fsdp-training-pytorch",
      "category": "artificial-intelligence",
      "title": "PyTorch Fully Sharded Data Parallel (FSDP) on AMD GPUs with ROCm",
      "date": "9 February 2025",
      "author": "Sean Song",
      "thumbnail": "2025-02-07-fsdp.jpg",
      "tags": [
        "AI/ML",
        "GenAI",
        "Fine-Tuning",
        "PyTorch"
      ],
      "description": "This blog guides you through the process of using PyTorch FSDP to fine-tune LLMs efficiently on AMD GPUs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "compute-memory-modes",
      "path": "blogs/software-tools-optimization/compute-memory-modes",
      "category": "software-tools-optimization",
      "title": "Deep dive into the MI300 compute and memory partition modes",
      "date": "9 Feb 2025",
      "author": "Muhammad Osama, Ryan Swann, Karthik Sangaiah, Sonali Singh, Ganesh Dasika, Rajneesh Bhardwaj",
      "thumbnail": "images/thumbnail.webp",
      "tags": [
        "HPC",
        "Installation",
        "Performance",
        "Scientific Computing"
      ],
      "description": "This blog explains how to use the MI300 compute and memory partitioning modes to optimize your performance-critical applications. ",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "mi300a-programming",
      "path": "blogs/software-tools-optimization/mi300a-programming",
      "category": "software-tools-optimization",
      "title": "MI300A - Exploring the APU advantage",
      "date": "9 Feb 2025",
      "author": "Suyash Tandon, Justin Chang",
      "thumbnail": "images/mi300a-die-package.webp",
      "tags": [
        "Compiler",
        "Memory",
        "HPC",
        "OpenMP"
      ],
      "description": "This blog post introduces the MI300 APU hardware, how it differs from other discrete systems, and how to leverage its GPU programming",
      "language": "English",
      "verticals": [
        "HPC",
        "Developers",
        "Systems"
      ]
    },
    {
      "slug": "k8s-orchestration-part1",
      "path": "blogs/artificial-intelligence/k8s-orchestration-part1",
      "category": "artificial-intelligence",
      "title": "AI Inference Orchestration with Kubernetes on Instinct MI300X, Part 1",
      "date": "07 February 2025",
      "author": "Victor Robles",
      "thumbnail": "2025-02-07-k8s-orch-pt1.jpg",
      "tags": [
        "Kubernetes",
        "LLM",
        "AI/ML",
        "GenAI"
      ],
      "description": "This blog is part 1 of a series aimed at providing a comprehensive, step-by-step guide for deploying and scaling AI inference workloads with Kubernetes and the AMD GPU Operator on the AMD Instinct platform",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "gemm_blog",
      "path": "blogs/artificial-intelligence/gemm_blog",
      "category": "artificial-intelligence",
      "title": "GEMM Kernel Optimization For AMD GPUs",
      "date": "6 February 2025",
      "author": "Ning Zhang, George Wang, Anshul Gupta",
      "thumbnail": "images/Thumbnail_487.webp",
      "tags": [
        "AI/ML"
      ],
      "description": "Guide to how GEMMs can be tuned for optimal performance of AI models on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "training_rocm_pt",
      "path": "blogs/artificial-intelligence/training_rocm_pt",
      "category": "artificial-intelligence",
      "title": "Enhancing AI Training with AMD ROCm Software",
      "date": "31 January 2025",
      "author": "Emad Barsoum",
      "thumbnail": "images/Training2.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "PyTorch"
      ],
      "description": "AMD's GPU training optimizations deliver peak performance for advanced AI models through ROCm software stack.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "LLM_Inference",
      "path": "blogs/artificial-intelligence/LLM_Inference",
      "category": "artificial-intelligence",
      "title": "Best practices for competitive inference optimization on AMD Instinct™ MI300X GPUs",
      "date": "29 Jan 2025",
      "author": "Andy Luo",
      "thumbnail": "images/Thumbnail_497.webp",
      "tags": [
        "LLM",
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Learn how to optimize large language model inference using vLLM on AMD's MI300X GPUs for enhanced performance and efficiency.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "gpu-operator-exporter",
      "path": "blogs/software-tools-optimization/gpu-operator-exporter",
      "category": "software-tools-optimization",
      "title": "Announcing the AMD GPU Operator and Metrics Exporter",
      "date": "29 Jan 2025",
      "author": "Farshad Ghodsian, Matt Elliott",
      "thumbnail": "2025-01-20-gpu-op.jpg",
      "tags": [
        "Kubernetes"
      ],
      "description": "This post announces the AMD GPU Operator for Kubernetes and and the Device Metrics Exporter, including instructions for getting started with these new releases.",
      "language": "English",
      "verticals": [
        "Systems"
      ]
    },
    {
      "slug": "mosaicml-composer",
      "path": "blogs/artificial-intelligence/mosaicml-composer",
      "category": "artificial-intelligence",
      "title": "Distributed fine-tuning of MPT-30B using Composer on AMD GPUs",
      "date": "28 Jan 2025",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "images/thumbnail-390.webp",
      "tags": [
        "LLM",
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "This blog uses Composer, a distributed framework, on AMD GPUs to fine-tune MPT-30B in single node as well as multinode",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vision-mamba",
      "path": "blogs/artificial-intelligence/vision-mamba",
      "category": "artificial-intelligence",
      "title": "Vision Mamba on AMD GPU with ROCm",
      "date": "24 January 2025",
      "author": "Sean Song",
      "thumbnail": "chip.jpeg",
      "tags": [
        "AI/ML",
        "GenAI",
        "Computer Vision",
        "PyTorch"
      ],
      "description": "This blog explores Vision Mamba (Vim), an innovative and efficient backbone for vision tasks and evaluate its performance on AMD GPUs with ROCm.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "rocm-containers",
      "path": "blogs/software-tools-optimization/rocm-containers",
      "category": "software-tools-optimization",
      "title": "Getting started with AMD ROCm containers: from base images to custom solutions",
      "date": "16 Jan 2025",
      "author": "Matt Elliott",
      "thumbnail": "2025-01-09-containers.png",
      "tags": [
        "AI/ML"
      ],
      "description": "This post, the second in a series, provides a walkthrough for building a vLLM container that can be used for both inference and benchmarking.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "ansys-fluent-performance",
      "path": "blogs/ecosystems-and-partners/ansys-fluent-performance",
      "category": "ecosystems-and-partners",
      "title": "Boosting Computational Fluid Dynamics Performance with AMD Instinct™ MI300X",
      "date": "14 Jan 2025",
      "author": "Martin Huarte",
      "thumbnail": "images/Ansys_Fluent_benchmarks_Blog.webp",
      "tags": [
        "HPC"
      ],
      "description": "The blog introduces CFD Ansys Fluent benchmarks and provides hands-on guide on installing and running four different Fluent models on AMD GPUs using ROCm.",
      "language": "English",
      "verticals": [
        "HPC"
      ]
    },
    {
      "slug": "triton_server_vllm",
      "path": "blogs/artificial-intelligence/triton_server_vllm",
      "category": "artificial-intelligence",
      "title": "Triton Inference Server with vLLM on AMD GPUs",
      "date": "8 January 2025",
      "author": "Fabricio Flores, Tiffany Mintz, Eliot Li, Yao Liu, Ted Themistokleous, Brian Pickrell, Vish Vadlamani",
      "thumbnail": "images/232285500_AMD_EPYC_Siena_beautyshot_02.webp",
      "tags": [
        "LLM",
        "AI/ML"
      ],
      "description": "This blog provides a how-to guide on setting up a Triton Inference Server with vLLM backend powered by AMD GPUs, showcasing robust performance with several LLMs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "zyphra",
      "path": "blogs/ecosystems-and-partners/zyphra",
      "category": "ecosystems-and-partners",
      "title": "Zyphra Introduces Frontier Training Kernels for Transformers and SSMs on AMD Instinct MI300X Accelerators",
      "date": "10 Dec 2024",
      "author": "Quentin Anthony",
      "thumbnail": "images/amd_zyphra.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "GenAI",
        "PyTorch"
      ],
      "description": "This blog shows Zyphra's new training kernels for transformers and hybrid models on AMD Instinct MI300X accelerators, surpassing the H100s performance",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "image-caption",
      "path": "blogs/artificial-intelligence/image-caption",
      "category": "artificial-intelligence",
      "title": "Transformer based Encoder-Decoder models for image-captioning on AMD GPUs",
      "date": "3 December 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "images/tabby-cat.webp",
      "tags": [
        "PyTorch",
        "AI/ML",
        "GenAI"
      ],
      "description": "The blog introduces image captioning and provides hands-on tutorials on three different Transformer-based encoder-decoder image captioning models: ViT-GPT2, BLIP, and Alpha- CLIP, deployed on AMD GPUs using ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "bnb-8bit",
      "path": "blogs/artificial-intelligence/bnb-8bit",
      "category": "artificial-intelligence",
      "title": "Quantized 8-bit LLM training and inference using bitsandbytes on AMD GPUs",
      "date": "13 November 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "images/precision.webp",
      "tags": [
        "LLM",
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Learn how to use bitsandbytes’ 8-bit representations techniques, 8-bit optimizer and LLM.int8, to optimize your LLMs training and inference using ROCm on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "sglang",
      "path": "blogs/artificial-intelligence/sglang",
      "category": "artificial-intelligence",
      "title": "SGLang: Fast Serving Framework for Large Language and Vision-Language Models on AMD GPUs",
      "date": "13 November 2024",
      "author": "Michael Zhang, Hai Xiao, Hui Liu, Yineng Zhang",
      "thumbnail": "images/cat_thumbnail2.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM",
        "PyTorch"
      ],
      "description": "Discover SGLang, a fast serving framework designed for large language and vision-language models on AMD GPUs, supporting efficient runtime and a flexible programming interface.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "fortran-journey",
      "path": "blogs/ecosystems-and-partners/fortran-journey",
      "category": "ecosystems-and-partners",
      "title": "Introducing AMD's Next-Gen Fortran Compiler",
      "date": "13 Nov 2024",
      "author": "Justin Chang, Brian Cornille, Michael Klemm, Johanna Potyka",
      "thumbnail": "images/Next-Gen-Fortran.webp",
      "tags": [
        "Compiler",
        "HPC",
        "Performance"
      ],
      "description": "In this post we present a brief preview of AMD's Next-Gen Fortran Compiler, our new open source Fortran complier optimized for AMD GPUs using OpenMP offloading, offering direct interface to ROCm and HIP.",
      "language": "English",
      "verticals": [
        "HPC",
        "Developers"
      ]
    },
    {
      "slug": "ddp-training-pytorch",
      "path": "blogs/artificial-intelligence/ddp-training-pytorch",
      "category": "artificial-intelligence",
      "title": "Distributed Data Parallel training on AMD GPU with ROCm",
      "date": "1 November 2024",
      "author": "Sean Song",
      "thumbnail": "images/ddp-amd.webp",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "PyTorch"
      ],
      "description": "This blog demonstrates how to speed up the training of a ResNet model on the CIFAR-100 classification task using PyTorch DDP on AMD GPUs with ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "ctranslate2",
      "path": "blogs/artificial-intelligence/ctranslate2",
      "category": "artificial-intelligence",
      "title": "CTranslate2: Efficient Inference with Transformer Models on AMD GPUs",
      "date": "24 October 2024",
      "author": "Michael Zhang",
      "thumbnail": "nlp.jpg",
      "tags": [
        "AI/ML",
        "GenAI",
        "LLM",
        "PyTorch"
      ],
      "description": "Optimizing Transformer models with CTranslate2 for efficient inference on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "torchtune",
      "path": "blogs/artificial-intelligence/torchtune",
      "category": "artificial-intelligence",
      "title": "Torchtune on AMD GPUs How-To Guide: Fine-tuning and Scaling LLMs with Multi-GPU Power",
      "date": "24 October 2024",
      "author": "Fabricio Flores",
      "thumbnail": "images/torchtune_blog.webp",
      "tags": [
        "PyTorch",
        "AI/ML",
        "LLM"
      ],
      "description": "Torchtune is a PyTorch library that enables efficient fine-tuning of LLMs. In this blog we use Torchtune to fine-tune the Llama-3.1-8B model for summarization tasks using LoRA and showcasing scalable training across multiple GPUs.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama3_2_vision",
      "path": "blogs/artificial-intelligence/llama3_2_vision",
      "category": "artificial-intelligence",
      "title": "Inference with Llama 3.2 Vision LLMs on AMD GPUs Using ROCm",
      "date": "23 October 2024",
      "author": "Sean Song",
      "thumbnail": "2024-10-31-inference-with-llama-3.2-vision.jpg",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "Meta's Llama 3.2 Vision models bring multimodal capabilities for vision-text tasks. This blog explores leveraging them on AMD GPUs with ROCm for efficient AI workflows.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "sdxl-multinode-oke",
      "path": "blogs/artificial-intelligence/sdxl-multinode-oke",
      "category": "artificial-intelligence",
      "title": "Multinode Fine-Tuning of Stable Diffusion XL on AMD GPUs with Hugging Face Accelerate and OCI's Kubernetes Engine (OKE)",
      "date": "15 October 2024",
      "author": "Douglas Jia",
      "thumbnail": "images/multinode-image.webp",
      "tags": [
        "AI/ML",
        "Fine-Tuning",
        "GenAI",
        "Diffusion Model"
      ],
      "description": "This blog demonstrates how to set-up and fine-tune a Stable Diffusion XL (SDXL) model in a multinode Oracle Cloud Infrastructure’s (OCI) Kubernetes Engine (OKE) on a cluster of AMD GPUs using ROCm",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "speculative-decoding",
      "path": "blogs/artificial-intelligence/speculative-decoding",
      "category": "artificial-intelligence",
      "title": "Speed Up Text Generation with Speculative Sampling on AMD GPUs",
      "date": "15 Oct, 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "images/speculative-decoding_thumbnail.webp",
      "tags": [
        "PyTorch",
        "AI/ML",
        "GenAI"
      ],
      "description": "This blog will introduce you to assisted text generation using Speculative Sampling. We briefly explain the principles underlying Speculative Sampling and demonstrate its implementation on AMD GPUs using ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "jax-triton",
      "path": "blogs/artificial-intelligence/jax-triton",
      "category": "artificial-intelligence",
      "title": "Supercharging JAX with Triton Kernels on AMD GPUs",
      "date": "9 October 2024",
      "author": "Clint Greene",
      "thumbnail": "images/AdobeStock_485944399.webp",
      "tags": [
        "AI/ML",
        "JAX",
        "LLM"
      ],
      "description": "In this blog post we guide you through developing a fused dropout activation kernel for matrices in Triton, calling the kernel from JAX, and benchmarking its performance.",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "int8-quantization",
      "path": "blogs/artificial-intelligence/int8-quantization",
      "category": "artificial-intelligence",
      "title": "Leaner LLM Inference with INT8 Quantization on AMD GPUs using PyTorch",
      "date": "3 October 2024",
      "author": "Douglas Jia",
      "thumbnail": "images/image_int8.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "PyTorch",
        "LLM",
        "Optimization",
        "Performance"
      ],
      "description": "This blog demonstrates how to use AMD GPUs to implement and evaluate INT8 quantization, and the derived inference speed-up of Llama family and Mistral LLM models.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science",
        "HPC"
      ]
    },
    {
      "slug": "axolotl",
      "path": "blogs/artificial-intelligence/axolotl",
      "category": "artificial-intelligence",
      "title": "Fine-tuning Llama 3 with Axolotl using ROCm on AMD GPUs",
      "date": "Sep 23 2024",
      "author": "Clint Greene",
      "thumbnail": "2024-06-18-tensorflow.jpg",
      "tags": [
        "AI/ML",
        "PyTorch",
        "LLM"
      ],
      "description": "This blog demonstrates how to fine-tune Llama 3 with Axolotl using ROCm on AMD GPUs, and how to evaluate the performance of your LLM before and after fine-tuning.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vllm",
      "path": "blogs/artificial-intelligence/vllm",
      "category": "artificial-intelligence",
      "title": "Inferencing and serving with vLLM on AMD GPUs",
      "date": "Sep 19 2024",
      "author": "Clint Greene",
      "thumbnail": "images/2024-10-31-inferencing-and-serving-with-vLLM-on-AMD-GPUs.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "Serving"
      ],
      "description": "Learn step-by-step how to leverage vLLM for high-performance inferencing and model serving on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "vllm-optimize",
      "path": "blogs/artificial-intelligence/vllm-optimize",
      "category": "artificial-intelligence",
      "title": "Enhancing vLLM Inference on AMD GPUs",
      "date": "Sep 19 2024",
      "author": "Clint Greene",
      "thumbnail": "2024-10-31-inferencing-and-serving-with-vLLM-on-AMD-GPUs.jpeg",
      "tags": [
        "AI/ML",
        "LLM",
        "Serving"
      ],
      "description": "Showcases the latest performance enhancements in vLLM inference on AMD Instinct accelerators using ROCm 6.2, including FP8 KV-Cache, quantization, and GEMM tuning",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "amd-smi-overview",
      "path": "blogs/software-tools-optimization/amd-smi-overview",
      "category": "software-tools-optimization",
      "title": "Getting to Know Your GPU: A Deep Dive into AMD SMI",
      "date": "17 Sep 2024",
      "author": "Matt Elliott",
      "thumbnail": "2024-10-31-amd-smi.jpeg",
      "tags": [
        "HPC",
        "Optimization",
        "Performance",
        "System-Tuning"
      ],
      "description": "This post introduces AMD System Management Interface (amd-smi), explaining how you can use it to access your GPU’s performance and status data",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "rocm-offline-installer",
      "path": "blogs/software-tools-optimization/rocm-offline-installer",
      "category": "software-tools-optimization",
      "title": "Introducing the AMD ROCm™ Offline Installer Creator: Simplifying Deployment for AI and HPC",
      "date": "10 Sep, 2024",
      "author": "Matt Elliott",
      "thumbnail": "2024-10-31-amd-rocm-offline-installer.jpeg",
      "tags": [
        "HPC",
        "Installation"
      ],
      "description": "Presenting and demonstrating the use of the ROCm Offline Installer Creator, a tool enabling simple deployment of ROCm in disconnected environments in high-security environments and air-gapped networks.",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "jax-mixed-precision",
      "path": "blogs/artificial-intelligence/jax-mixed-precision",
      "category": "artificial-intelligence",
      "title": "Optimize GPT Training: Enabling Mixed Precision Training in JAX using ROCm on AMD GPUs",
      "date": "6 Sept 2024",
      "author": "Douglas Jia",
      "thumbnail": "images/optimize-gpt-training.webp",
      "tags": [
        "AI/ML",
        "GenAI",
        "JAX",
        "LLM"
      ],
      "description": "Guide to modify our JAX-based nanoGPT model for mixed-precision training, optimizing speed and efficiency on AMD GPUs with ROCm.",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "image-classification",
      "path": "blogs/artificial-intelligence/image-classification",
      "category": "artificial-intelligence",
      "title": "Image Classification with BEiT, MobileNet, and EfficientNet using ROCm on AMD GPUs",
      "date": "3 Sept, 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "2024-10-03-image_classification.jpg",
      "tags": [
        "Computer Vision",
        "PyTorch",
        "AI/ML"
      ],
      "description": "Image Classification with BEiT, MobileNet, and EfficientNet on AMD GPU",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "seismic-stencils/part-1",
      "path": "blogs/high-performance-computing/seismic-stencils/part-1",
      "category": "high-performance-computing",
      "title": "Seismic stencil codes - part 1",
      "date": "29 Aug 2024",
      "author": "Justin Chang, Ossian O'Reilly",
      "thumbnail": "2024-10-10-seismic.jpeg",
      "tags": [
        "HPC",
        "Memory",
        "Performance",
        "Profiling",
        "Scientific Computing"
      ],
      "description": "Seismic Stencil Codes - Part 1: Seismic workloads in the HPC space have a long history of being powered by high-order finite difference methods on structured grids. This trend continues to this day.",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "seismic-stencils/part-2",
      "path": "blogs/high-performance-computing/seismic-stencils/part-2",
      "category": "high-performance-computing",
      "title": "Seismic stencil codes - part 2",
      "date": "29 Aug 2024",
      "author": "Justin Chang, Ossian O'Reilly",
      "thumbnail": "2024-10-10-seismic.jpeg",
      "tags": [
        "HPC",
        "Memory",
        "Performance",
        "Profiling",
        "Optimization",
        "Scientific Computing"
      ],
      "description": "Seismic Stencil Codes - Part 2: In the previous post, recall that the kernel with stencil computation in the z-direction suffered from low effective bandwidth. This low performance comes from generating substantial amounts of data to movement to global memory.",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems",
        "Data Science"
      ]
    },
    {
      "slug": "seismic-stencils/part-3",
      "path": "blogs/high-performance-computing/seismic-stencils/part-3",
      "category": "high-performance-computing",
      "title": "Seismic stencil codes - part 3",
      "date": "29 Aug 2024",
      "author": "Justin Chang, Ossian O'Reilly",
      "thumbnail": "2024-10-10-seismic.jpeg",
      "tags": [
        "HPC",
        "Memory",
        "Performance",
        "Profiling",
        "Optimization",
        "Scientific Computing"
      ],
      "description": "Seismic Stencil Codes - Part 3: In the last two blog posts, we developed a HIP kernel capable of computing high order finite differences commonly needed in seismic wave propagation.",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems",
        "Data Science"
      ]
    },
    {
      "slug": "mlperf-inf-4-1",
      "path": "blogs/artificial-intelligence/mlperf-inf-4-1",
      "category": "artificial-intelligence",
      "title": "Benchmarking Machine Learning using ROCm and AMD GPUs: Reproducing Our MLPerf Inference Submission",
      "date": "28 Aug 2024",
      "author": "Meena Arunachalam, Miro Hodak, Jeremy Arnold, Eliot Li",
      "thumbnail": "2024-10-03-mlperf.jpeg",
      "tags": [
        "AI/ML",
        "LLM"
      ],
      "description": "Benchmarking Machine Learning using ROCm and AMD GPUs: Reproducing Our MLPerf Inference Submission",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llm-tasks",
      "path": "blogs/artificial-intelligence/llm-tasks",
      "category": "artificial-intelligence",
      "title": "Performing natural language processing tasks with LLMs on ROCm running on AMD GPUs",
      "date": "21 August 2024",
      "author": "Eliot Li",
      "thumbnail": "2024-10-03-llm-tasks.jpeg",
      "tags": [
        "AI/ML",
        "LLM"
      ],
      "description": "Performing natural language processing tasks with LLMs on ROCm running on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "timeseries_transformers",
      "path": "blogs/artificial-intelligence/timeseries_transformers",
      "category": "artificial-intelligence",
      "title": "Using AMD GPUs for Enhanced Time Series Forecasting with Transformers",
      "date": "19 Aug 2024",
      "author": "Fabricio Flores",
      "thumbnail": "2024-10-10-timeseries.jpeg",
      "tags": [
        "AI/ML",
        "LLM",
        "PyTorch",
        "Time Series"
      ],
      "description": "Time series forecasting (TSF) predicts future behavior using past data. This guide focuses on implementing Transformers for TSF, covering preprocessing to evaluation using AMD hardware.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "grok1",
      "path": "blogs/artificial-intelligence/grok1",
      "category": "artificial-intelligence",
      "title": "Inferencing with Grok-1 on AMD GPUs",
      "date": "9 Aug 2024",
      "author": "Eliot Li, Luise Chen, Lei Shao",
      "thumbnail": "2024-10-10-grok1.jpeg",
      "tags": [
        "AI/ML",
        "LLM"
      ],
      "description": "We demonstrate that the massive Grok-1 Model from xAI can run seamlessly on the AMD MI300X GPU accelerator by leveraging the ROCm software platform.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "roberta_amp",
      "path": "blogs/artificial-intelligence/roberta_amp",
      "category": "artificial-intelligence",
      "title": "Optimizing RoBERTa: Fine-Tuning with Mixed Precision on AMD",
      "date": "29 July 2024",
      "author": "Fabricio Flores",
      "thumbnail": "images/roberta_amp_thumbnail.webp",
      "tags": [
        "PyTorch",
        "AI/ML",
        "LLM",
        "Optimization"
      ],
      "description": "In this blog we explore how to fine-tune the Robustly Optimized BERT Pretraining Approach RoBERTa large language model, with emphasis on PyTorch's mixed precision capabilities. Specifically, we explore using AMD GPUs for mixed precision fine-tuning to achieve faster model training without any major impacts on accuracy.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "graphs",
      "path": "blogs/high-performance-computing/graphs",
      "category": "high-performance-computing",
      "title": "Graph analytics on AMD GPUs using Gunrock",
      "date": "29 July 2024",
      "author": "Thomas Gibson, Muhammad Osama",
      "thumbnail": "2024-10-10-gunrock.jpg",
      "tags": [
        "HPC",
        "Installation",
        "Performance",
        "Scientific Computing"
      ],
      "description": "Graph analytics on AMD GPUs using Gunrock",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "jax-profiler",
      "path": "blogs/artificial-intelligence/jax-profiler",
      "category": "artificial-intelligence",
      "title": "Using statistical methods to reliably compare algorithm performance in large generative AI models with JAX Profiler on AMD GPUs",
      "date": "22 July 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "JAX",
        "AI/ML",
        "Optimization",
        "Profiling"
      ],
      "description": "Using Statistical Methods to Reliably Compare Algorithm Performance in Large Generative AI Models with JAX Profiler on AMD GPUs",
      "language": "English",
      "verticals": [
        "Developers",
        "AI",
        "Data Science",
        "HPC"
      ]
    },
    {
      "slug": "dbrx",
      "path": "blogs/artificial-intelligence/dbrx",
      "category": "artificial-intelligence",
      "title": "DBRX Instruct on AMD GPUs",
      "date": "11 July 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML"
      ],
      "description": "DBRX Instruct on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "torch_compile",
      "path": "blogs/artificial-intelligence/torch_compile",
      "category": "artificial-intelligence",
      "title": "Accelerate PyTorch Models using torch.compile on AMD GPUs with ROCm",
      "date": "11 July 2024",
      "author": "Sean Song",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Computer Vision",
        "Compiler",
        "PyTorch"
      ],
      "description": "Accelerate PyTorch Models using torch.compile on AMD GPUs with ROCm",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science",
        "Developers"
      ]
    },
    {
      "slug": "pytorch-tunableop",
      "path": "blogs/artificial-intelligence/pytorch-tunableop",
      "category": "artificial-intelligence",
      "title": "Accelerating models on ROCm using PyTorch TunableOp",
      "date": "3 July 2024",
      "author": "Logan Grado",
      "thumbnail": "",
      "tags": [
        "Optimization",
        "LLM",
        "GenAI",
        "Linear Algebra",
        "PyTorch"
      ],
      "description": "Accelerating models on ROCm using PyTorch TunableOp",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "nanoGPT-JAX",
      "path": "blogs/artificial-intelligence/nanoGPT-JAX",
      "category": "artificial-intelligence",
      "title": "A Guide to Implementing and Training Generative Pre-trained Transformers (GPT) in JAX on AMD GPUs",
      "date": "2 July 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "JAX",
        "PyTorch",
        "LLM"
      ],
      "description": "A Guide to Implementing and Training Generative Pre-trained Transformers (GPT) in JAX on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "dlrm",
      "path": "blogs/artificial-intelligence/dlrm",
      "category": "artificial-intelligence",
      "title": "Deep Learning Recommendation Models on AMD GPUs",
      "date": "28 Jun 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch"
      ],
      "description": "Deep Learning Recommendation Model on AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "mamba",
      "path": "blogs/artificial-intelligence/mamba",
      "category": "artificial-intelligence",
      "title": "Mamba on AMD GPUs with ROCm",
      "date": "28 Jun 2024",
      "author": "Sean Song, Jassani Adeem, Moskvichev Arseny",
      "thumbnail": "2024-07-29-roberta.jpg",
      "tags": [
        "LLM",
        "GenAI",
        "Performance"
      ],
      "description": "Best practices of using Mamba on AMD GPUs with ROCm",
      "language": "English",
      "verticals": [
        "AI",
        "HPC"
      ]
    },
    {
      "slug": "speech_models",
      "path": "blogs/artificial-intelligence/speech_models",
      "category": "artificial-intelligence",
      "title": "Fine-tuning and Testing Cutting-Edge Speech Models using ROCm on AMD GPUs",
      "date": "27 Jun 2024",
      "author": "Fabricio Flores",
      "thumbnail": "images/thumb_speech_models.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "PyTorch",
        "Speech"
      ],
      "description": "This blog post demonstrates how to fine-tune and test three state-of-the-art machine learning Automatic Speech Recognition (ASR) models, running on AMD GPUs using ROCm.",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "tf_profiler",
      "path": "blogs/software-tools-optimization/tf_profiler",
      "category": "software-tools-optimization",
      "title": "TensorFlow Profiler in practice: Optimizing TensorFlow models on AMD GPUs",
      "date": "18 Jun 2024",
      "author": "Fabricio Flores",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "Profiling",
        "HPC"
      ],
      "description": "TensorFlow Profiler measures resource use and performance of models, helping identify bottlenecks for optimization. This blog demonstrates the use of the TensorFlow Profiler tool on AMD hardware.",
      "language": "English",
      "verticals": [
        "HPC",
        "AI"
      ]
    },
    {
      "slug": "stone-ridge",
      "path": "blogs/ecosystems-and-partners/stone-ridge",
      "category": "ecosystems-and-partners",
      "title": "Stone Ridge Expands Reservoir Simulation Options with AMD Instinct™ Accelerators",
      "date": "10 June 2024",
      "author": "Unknown",
      "thumbnail": "stone-ridge.jpg",
      "tags": [
        "Partner Applications"
      ],
      "description": "Stone Ridge Technology (SRT) pioneered the use of GPUs for high performance reservoir simulation (HPC) nearly a decade ago with ECHELON, its flagship software product. ECHELON, the first of its kind, engineered from the outset to harness the full potential of massively parallel GPUs, stands apart in the industry for its power, efficiency, and accuracy. Now, ECHELON has added support for AMDInstinct accelerators into its simulation engine, offering new flexibility and optionality to its clients.",
      "language": "English",
      "verticals": [
        "Systems"
      ]
    },
    {
      "slug": "segment-anything",
      "path": "blogs/artificial-intelligence/segment-anything",
      "category": "artificial-intelligence",
      "title": "Segment Anything with AMD GPUs",
      "date": "4 Jun 2024",
      "author": "Sean Song",
      "thumbnail": "",
      "tags": [
        "Computer Vision",
        "AI/ML"
      ],
      "description": "Segment Anything with AMD GPUs",
      "language": "English",
      "verticals": [
        "Data Science",
        "AI"
      ]
    },
    {
      "slug": "ck-int8-gemm-sq",
      "path": "blogs/software-tools-optimization/ck-int8-gemm-sq",
      "category": "software-tools-optimization",
      "title": "SmoothQuant model inference on AMD Instinct MI300X using Composable Kernel",
      "date": "31 May 2024",
      "author": "Cheng Ling",
      "thumbnail": "",
      "tags": [
        "LLM",
        "Linear Algebra"
      ],
      "description": "SmoothQuant model inference on AMD Instinct MI300X using Composable Kernel",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "torch_profiler",
      "path": "blogs/artificial-intelligence/torch_profiler",
      "category": "artificial-intelligence",
      "title": "Unveiling performance insights with PyTorch Profiler on an AMD GPU",
      "date": "29 May 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Tuning"
      ],
      "description": "Unveiling Performance Insights with PyTorch Profiler on an AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "detectron2",
      "path": "blogs/artificial-intelligence/detectron2",
      "category": "artificial-intelligence",
      "title": "Panoptic segmentation and instance segmentation with Detectron2 on AMD GPUs",
      "date": "23 May 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Reinforcement Learning",
        "Computer Vision"
      ],
      "description": "Object Detection and Image Segmentation with Detectron2 on AMD GPU",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "Siemens",
      "path": "blogs/ecosystems-and-partners/Siemens",
      "category": "ecosystems-and-partners",
      "title": "Siemens taps AMD Instinct™ GPUs to expand high-performance hardware options for Simcenter STAR-CCM+",
      "date": "16 May 2024",
      "author": "Unknown",
      "thumbnail": "siemens.jpg",
      "tags": [
        "Partner Applications",
        "Data Science"
      ],
      "description": "Siemens recently announced that its Simcenter STAR-CCM+ multi-physics computational fluid dynamics (CFD) software now supports AMD Instinct™ GPUs for GPU-native computation. This move addresses its users' needs for computational efficiency, reduced simulation costs and energy usage, and greater hardware choice.",
      "language": "English",
      "verticals": [
        "Developers, Data Science"
      ]
    },
    {
      "slug": "university-of-michigan",
      "path": "blogs/ecosystems-and-partners/university-of-michigan",
      "category": "ecosystems-and-partners",
      "title": "AMD Collaboration with the University of Michigan offers High Performance Open-Source Solutions to the Bioinformatics Community",
      "date": "16 May 2024",
      "author": "Unknown",
      "thumbnail": "university-of-michigan-bioinformatics.jpg",
      "tags": [
        "Partner Applications"
      ],
      "description": "We are thrilled to share the success story of a 1.5-year collaboration between AMD and the University of Michigan, Ann Arbor where we used the AMD Instinct™ GPUs and ROCm™ software stack to optimize the sequence alignment bottleneck in long read processing workflows.",
      "language": "English",
      "verticals": [
        "Systems"
      ]
    },
    {
      "slug": "flash-attention",
      "path": "blogs/artificial-intelligence/flash-attention",
      "category": "artificial-intelligence",
      "title": "Accelerating Large Language Models with Flash Attention on AMD GPUs",
      "date": "15 May 2024",
      "author": "Clint Greene",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "PyTorch",
        "LLM"
      ],
      "description": "Accelerating Large Language Models with Flash Attention on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "amdgcn-isa",
      "path": "blogs/software-tools-optimization/amdgcn-isa",
      "category": "software-tools-optimization",
      "title": "Reading AMD GPU ISA",
      "date": "13 May 2024",
      "author": "Asitav Mishra, Corbin Robeck",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "Compiler",
        "HPC",
        "Memory"
      ],
      "description": "Reading AMDGCN ISA",
      "language": "English",
      "verticals": [
        "Developers",
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "roc-profiling",
      "path": "blogs/software-tools-optimization/roc-profiling",
      "category": "software-tools-optimization",
      "title": "AMD in Action: Unveiling the Power of Application Tracing and Profiling",
      "date": "7 May 2024",
      "author": "Fabricio Flores",
      "thumbnail": "",
      "tags": [
        "Profiling",
        "HPC"
      ],
      "description": "AMD in Action: Unveiling the Power of Application Tracing and Profiling",
      "language": "English",
      "verticals": [
        "HPC"
      ]
    },
    {
      "slug": "moe",
      "path": "blogs/artificial-intelligence/moe",
      "category": "artificial-intelligence",
      "title": "Inferencing with Mixtral 8x22B on AMD GPUs",
      "date": "1 May 2024",
      "author": "Clint Greene",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "LLM"
      ],
      "description": "Inferencing with Mixtral 8x22B on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "openllm",
      "path": "blogs/artificial-intelligence/openllm",
      "category": "artificial-intelligence",
      "title": "Step-by-Step Guide to Use OpenLLM on AMD GPUs",
      "date": "1 May 2024",
      "author": "Fabricio Flores",
      "thumbnail": "images/openllm_thumbnail.webp",
      "tags": [
        "AI/ML",
        "LLM",
        "Serving"
      ],
      "description": "OpenLLM is an open-source platform for deploying large language models, enabling cloud or on-premises use. In this blog we focus on using OpenLLM to start an LLM server leveraging the capabilities of AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "ncf",
      "path": "blogs/artificial-intelligence/ncf",
      "category": "artificial-intelligence",
      "title": "Training a Neural Collaborative Filtering (NCF) Recommender on an AMD GPU",
      "date": "30 Apr 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "TensorFlow",
        "AI/ML",
        "Recommendation Systems"
      ],
      "description": "Training a Neural Collaborative Filtering (NCF) Recommender on an AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llava-next",
      "path": "blogs/artificial-intelligence/llava-next",
      "category": "artificial-intelligence",
      "title": "Multimodal (Visual and Language) understanding with LLaVA-NeXT",
      "date": "26 Apr 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Multimodal",
        "Fine-Tuning",
        "LLM"
      ],
      "description": "Multimodal instruction-following data with LLaVA-NeXT on AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "TaPas",
      "path": "blogs/artificial-intelligence/TaPas",
      "category": "artificial-intelligence",
      "title": "Table Question-Answering with TaPas",
      "date": "26 Apr 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "LLM",
        "Fine-Tuning"
      ],
      "description": "Table Question-Answering with TaPas",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "hipify",
      "path": "blogs/software-tools-optimization/hipify",
      "category": "software-tools-optimization",
      "title": "Application portability with HIP",
      "date": "26 Apr 2024",
      "author": "Suyash Tandon, Maria Ruiz Varela, Gina Sitaraman, Bob Robey",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "Compiler",
        "Installation",
        "HPC",
        "Optimization"
      ],
      "description": "Application portability with HIP",
      "language": "English",
      "verticals": [
        "Developers",
        "Systems",
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "text-to-video-generation",
      "path": "blogs/artificial-intelligence/text-to-video-generation",
      "category": "artificial-intelligence",
      "title": "Transforming Words into Motion: A Guide to Video Generation with AMD GPU",
      "date": "24 Apr 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "PyTorch"
      ],
      "description": "Transforming Words into Motion: A Guide to Video Generation with AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "vision-text-dual-encoding",
      "path": "blogs/artificial-intelligence/vision-text-dual-encoding",
      "category": "artificial-intelligence",
      "title": "Unlocking Vision-Text Dual-Encoding: Multi-GPU Training of a CLIP-Like Model",
      "date": "24 Apr 2024",
      "author": "Sean Song",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning",
        "PyTorch",
        "Computer Vision"
      ],
      "description": "Unlocking Vision-Text Dual-Encoding: Multi-GPU Training of a CLIP-Like Model",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "hipstdpar",
      "path": "blogs/software-tools-optimization/hipstdpar",
      "category": "software-tools-optimization",
      "title": "C++17 parallel algorithms and HIPSTDPAR #",
      "date": "18 Apr 2024",
      "author": "Alessandro Fanfarillo, Alex Voicu",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "C++",
        "Compiler",
        "HPC",
        "Memory",
        "Performance"
      ],
      "description": "C++17 parallel algorithms and HIPSTDPAR",
      "language": "English",
      "verticals": [
        "Developers",
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "ai2-olmo",
      "path": "blogs/artificial-intelligence/ai2-olmo",
      "category": "artificial-intelligence",
      "title": "Inferencing with AI2's OLMo model on AMD GPU",
      "date": "17 Apr 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "PyTorch",
        "Diffusion Model",
        "LLM"
      ],
      "description": "Inferencing with AI2's OLMo model on AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "CLIP",
      "path": "blogs/artificial-intelligence/CLIP",
      "category": "artificial-intelligence",
      "title": "Interacting with Contrastive Language-Image Pre-Training (CLIP) model on AMD GPU",
      "date": "16 April 2024",
      "author": "Sean Song",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "Computer Vision",
        "Multimodal"
      ],
      "description": "Interacting with Contrastive Language-Image Pre-Training (CLIP) model on AMD GPU",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "CodeGen",
      "path": "blogs/artificial-intelligence/CodeGen",
      "category": "artificial-intelligence",
      "title": "Program Synthesis with CodeGen",
      "date": "16 Apr 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "GenAI"
      ],
      "description": "Program Synthesis with CodeGen",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "cpp-extn",
      "path": "blogs/artificial-intelligence/cpp-extn",
      "category": "artificial-intelligence",
      "title": "PyTorch C++ Extension on AMD GPU",
      "date": "16 Apr, 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "C++",
        "PyTorch",
        "AI/ML"
      ],
      "description": "PyTorch C++ Extension on AMD hardware",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "FlanT5",
      "path": "blogs/artificial-intelligence/FlanT5",
      "category": "artificial-intelligence",
      "title": "Text Summarization with FLAN-T5",
      "date": "16 April 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Text Summarization with FLAN-T5 on AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "starcoder-fine-tune",
      "path": "blogs/artificial-intelligence/starcoder-fine-tune",
      "category": "artificial-intelligence",
      "title": "Instruction fine-tuning of StarCoder with PEFT on multiple AMD GPUs",
      "date": "16 Apr 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "PyTorch",
        "Fine-Tuning"
      ],
      "description": "Instruction fine tuning of StarCoder with PEFT on multiple AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "whisper",
      "path": "blogs/artificial-intelligence/whisper",
      "category": "artificial-intelligence",
      "title": "Speech-to-Text on an AMD GPU with Whisper",
      "date": "16 Apr 2024",
      "author": "Clint Greene",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "Speech",
        "Computer Vision"
      ],
      "description": "Speech to Text on AMD with Whisper",
      "language": "English",
      "verticals": [
        "Data Science",
        "AI"
      ]
    },
    {
      "slug": "affinity/part-1",
      "path": "blogs/software-tools-optimization/affinity/part-1",
      "category": "software-tools-optimization",
      "title": " Affinity part 1 - Affinity, placement, and order",
      "date": "16 Apr 2024",
      "author": "Gina Sitaraman, Bob Robey, George Markomanolis",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory",
        "OpenMP",
        "Performance",
        "System-Tuning"
      ],
      "description": "Affinity Part 1",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "affinity/part-2",
      "path": "blogs/software-tools-optimization/affinity/part-2",
      "category": "software-tools-optimization",
      "title": "Affinity part 2 - System topology and controlling affinity",
      "date": "16 Apr 2024",
      "author": "Gina Sitaraman, Bob Robey, George Markomanolis",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory",
        "OpenMP",
        "Performance",
        "System-Tuning"
      ],
      "description": "Affinity Part 2",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "julia-amdgpu",
      "path": "blogs/software-tools-optimization/julia-amdgpu",
      "category": "software-tools-optimization",
      "title": "Programming AMD GPUs with Julia",
      "date": "16 Apr 2024",
      "author": "Anton Smirnov",
      "thumbnail": "",
      "tags": [
        "HPC",
        "AI/ML",
        "Scientific Computing",
        "Developers",
        "Data Science"
      ],
      "description": "Programming AMD GPUs with Julia",
      "language": "English",
      "verticals": [
        "AI, HPC, Developers, Data Science"
      ]
    },
    {
      "slug": "llama-Qlora",
      "path": "blogs/artificial-intelligence/llama-Qlora",
      "category": "artificial-intelligence",
      "title": "Enhancing LLM Accessibility: A Deep Dive into QLoRA Through Fine-tuning Llama Model on a single AMD GPU",
      "date": "15 April 2024",
      "author": "Sean Song",
      "thumbnail": "image.jpg",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "This blog demonstrate how to use QLora to efficiently fine-tune Llama model on a single AMD GPU with ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama2-Qlora",
      "path": "blogs/artificial-intelligence/llama2-Qlora",
      "category": "artificial-intelligence",
      "title": "Enhancing LLM Accessibility: A Deep Dive into QLoRA Through Fine-tuning Llama 2 on a single AMD GPU",
      "date": "15 Apr 2024",
      "author": "Sean Song",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "LLM",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "Enhancing LLM Accessibility: A Deep Dive into QLoRA Through Fine-tuning Llama 2 on a single AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "triton",
      "path": "blogs/artificial-intelligence/triton",
      "category": "artificial-intelligence",
      "title": "Developing Triton Kernels on AMD GPUs",
      "date": "15 April 2024",
      "author": "Clint Greene",
      "thumbnail": "generic.jpg",
      "tags": [
        "AI/ML"
      ],
      "description": "This blog shows users how to develop and benchmark a custom Triton kernel",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "reinforcement-learning-gym",
      "path": "blogs/artificial-intelligence/reinforcement-learning-gym",
      "category": "artificial-intelligence",
      "title": "GPU Unleashed: Training Reinforcement Learning Agents with Stable Baselines3 on an AMD GPU in Gymnasium Environment",
      "date": "11 Apr 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "PyTorch",
        "Reinforcement Learning"
      ],
      "description": "GPU Unleashed: Training Reinforcement Learning Agents with Stable Baselines3 on an AMD GPU in Gymnasium Environment",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "resnet",
      "path": "blogs/artificial-intelligence/resnet",
      "category": "artificial-intelligence",
      "title": "ResNet for image classification using AMD GPUs",
      "date": "9 April 2024",
      "author": "Logan Grado",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "Reinforcement Learning",
        "PyTorch",
        "Computer Vision"
      ],
      "description": "ResNet for image classification using AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "Phi2",
      "path": "blogs/artificial-intelligence/Phi2",
      "category": "artificial-intelligence",
      "title": "Small language models with Phi-2",
      "date": "8 Apr 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Small language models with Phi-2",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "ChatGLM",
      "path": "blogs/artificial-intelligence/ChatGLM",
      "category": "artificial-intelligence",
      "title": "Using the ChatGLM-6B bilingual language model with AMD GPUs",
      "date": "4 April 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "LLM"
      ],
      "description": "Bilingual language model ChatGLM-6B",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "monai-deploy",
      "path": "blogs/artificial-intelligence/monai-deploy",
      "category": "artificial-intelligence",
      "title": "Total body segmentation using MONAI Deploy on an AMD GPU",
      "date": "4 Apr 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Computer Vision"
      ],
      "description": "Total body segmentation using MONAI Deploy with ROCm",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "rag-llamaindex",
      "path": "blogs/artificial-intelligence/rag-llamaindex",
      "category": "artificial-intelligence",
      "title": "Retrieval Augmented Generation (RAG) using LlamaIndex",
      "date": "04 Apr 2024",
      "author": "Clint Greene",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML"
      ],
      "description": "Retrieval Augmented Generation (RAG) using LlamaIndex",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "sentence_transformers_amd",
      "path": "blogs/artificial-intelligence/sentence_transformers_amd",
      "category": "artificial-intelligence",
      "title": "Building semantic search with SentenceTransformers on AMD",
      "date": "4 Apr 2024",
      "author": "Fabricio Flores",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Computer Vision"
      ],
      "description": "Building semantic search with SentenceTransformers on AMD",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "vit-inference",
      "path": "blogs/artificial-intelligence/vit-inference",
      "category": "artificial-intelligence",
      "title": "Image classification using Vision Transformer with AMD GPUs",
      "date": "4 Apr 2024",
      "author": "Eliot Li",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "Computer Vision"
      ],
      "description": "Image classification using Vision Transformer with AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Data Science"
      ]
    },
    {
      "slug": "ray",
      "path": "blogs/artificial-intelligence/ray",
      "category": "artificial-intelligence",
      "title": "Scale AI applications with Ray",
      "date": "1 Apr 2024",
      "author": "Vicky Tsang, Logan Grado, Eliot Li",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning",
        "Diffusion Model"
      ],
      "description": "Scale AI applications with Ray",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "automatic-mixed-precision",
      "path": "blogs/artificial-intelligence/automatic-mixed-precision",
      "category": "artificial-intelligence",
      "title": "Automatic mixed precision in PyTorch using AMD GPUs.",
      "date": "29 March 2024",
      "author": "Logan Grado",
      "thumbnail": "images/amp_thumbnail.webp",
      "tags": [
        "PyTorch",
        "AI/ML"
      ],
      "description": "In this blog, we will discuss the basics of AMP, how it works, and how it can improve training efficiency on AMD GPUs. As models increase in size, the time and memory needed to train them--and consequently, the cost--also increases. Therefore, any measures we take to reduce training time and memory usage can be highly beneficial. This is where Automatic Mixed Precision (AMP) comes in.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llm-inference-optimize",
      "path": "blogs/artificial-intelligence/llm-inference-optimize",
      "category": "artificial-intelligence",
      "title": "Large language model inference optimizations on AMD GPUs",
      "date": "15 Mar 2024",
      "author": "Seungrok Jung",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "LLM Inference optimizations on AMD Instinct (TM) GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "decoder-transformer",
      "path": "blogs/artificial-intelligence/decoder-transformer",
      "category": "artificial-intelligence",
      "title": "Building a decoder transformer model on AMD GPU(s)",
      "date": "12 Mar 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Building a decoder transformer model",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "langchain-chatbot",
      "path": "blogs/artificial-intelligence/langchain-chatbot",
      "category": "artificial-intelligence",
      "title": "Question-answering Chatbot with LangChain on an AMD GPU",
      "date": "11 Mar 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Question-answering Chatbot with LangChain",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "MusicGen",
      "path": "blogs/artificial-intelligence/MusicGen",
      "category": "artificial-intelligence",
      "title": "Music Generation With MusicGen on an AMD GPU",
      "date": "8 Mar 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "Music Generation With MusicGen on an AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "stable-diffusion-onnx-runtime",
      "path": "blogs/artificial-intelligence/stable-diffusion-onnx-runtime",
      "category": "artificial-intelligence",
      "title": "Efficient image generation with Stable Diffusion models and ONNX Runtime using AMD GPUs",
      "date": "23 Feb 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "PyTorch",
        "Diffusion Model"
      ],
      "description": "Efficient image generation with Stable Diffusion models and ONNX Runtime using AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "pytorch-lightning",
      "path": "blogs/artificial-intelligence/pytorch-lightning",
      "category": "artificial-intelligence",
      "title": "Simplifying deep learning: A guide to PyTorch Lightning",
      "date": "8 Feb 2024",
      "author": "Phillip Dang",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Simplifying deep learning: A guide to PyTorch Lightning",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "nerf",
      "path": "blogs/artificial-intelligence/nerf",
      "category": "artificial-intelligence",
      "title": "Two-dimensional images to three-dimensional scene mapping using NeRF on an AMD GPU",
      "date": "7 Feb 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "PyTorch",
        "AI/ML",
        "GenAI"
      ],
      "description": "Two-dimensional images to three-dimensional scene mapping using NeRF on an AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "lora-fundamentals",
      "path": "blogs/artificial-intelligence/lora-fundamentals",
      "category": "artificial-intelligence",
      "title": "Using LoRA for efficient fine-tuning: Fundamental principles",
      "date": "5 Feb 2024",
      "author": "Sean Song",
      "thumbnail": "image.jpg",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning",
        "PyTorch"
      ],
      "description": "This blog demonstrate how to use Lora to efficiently fine-tune Llama model on AMD GPUs with ROCm.",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama-lora",
      "path": "blogs/artificial-intelligence/llama-lora",
      "category": "artificial-intelligence",
      "title": "Fine-tune Llama model with LoRA: Customizing a large language model for question-answering",
      "date": "1 Feb 2024",
      "author": "Sean Song",
      "thumbnail": "image.jpg",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "This blog demonstrate how to use Lora to efficiently fine-tune Llama model on a single AMD GPU with ROCm. model for question-answering",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "llama2-lora",
      "path": "blogs/artificial-intelligence/llama2-lora",
      "category": "artificial-intelligence",
      "title": "Fine-tune Llama 2 with LoRA: Customizing a large language model for question-answering",
      "date": "01 Feb 2024",
      "author": "Sean Song",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "LLM",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "Fine-tune Llama 2 with LoRA: Customizing a large language model for question-answering",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "bert-hg-tf",
      "path": "blogs/artificial-intelligence/bert-hg-tf",
      "category": "artificial-intelligence",
      "title": "Pre-training BERT using Hugging Face & TensorFlow on an AMD GPU",
      "date": "29 Jan 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning"
      ],
      "description": "Pre-training BERT using Hugging Face & Tensorflow on an AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "bert-hg-pytorch",
      "path": "blogs/artificial-intelligence/bert-hg-pytorch",
      "category": "artificial-intelligence",
      "title": "Pre-training BERT using Hugging Face & PyTorch on an AMD GPU",
      "date": "26 Jan 2024",
      "author": "Vara Lakshmi Bayanagari",
      "thumbnail": "",
      "tags": [
        "LLM",
        "GenAI",
        "PyTorch",
        "AI/ML",
        "Fine-Tuning"
      ],
      "description": "Pre-training BERT using Hugging Face & PyTorch on an AMD GPU",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "xgboost-multi-gpu",
      "path": "blogs/artificial-intelligence/xgboost-multi-gpu",
      "category": "artificial-intelligence",
      "title": "Accelerating XGBoost with Dask using multiple AMD GPUs",
      "date": "26 Jan 2024",
      "author": "Clint Greene",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML"
      ],
      "description": "Accelerating XGBoost with Dask using multiple AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "distributed-sft-jax",
      "path": "blogs/artificial-intelligence/distributed-sft-jax",
      "category": "artificial-intelligence",
      "title": "LLM distributed supervised fine-tuning with JAX",
      "date": "25 Jan 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI",
        "Fine-Tuning",
        "JAX"
      ],
      "description": "LLM distributed supervised fine-tuning with JAX",
      "language": "English",
      "verticals": [
        "AI",
        "Developers"
      ]
    },
    {
      "slug": "hf-tgi",
      "path": "blogs/artificial-intelligence/hf-tgi",
      "category": "artificial-intelligence",
      "title": "Efficient deployment of large language models with Text Generation Inference on AMD GPUs",
      "date": "24 Jan 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "GenAI"
      ],
      "description": "Efficient deployment of large language models with Hugging Face text generation inference empowered by AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "megatron-deepspeed-pretrain",
      "path": "blogs/artificial-intelligence/megatron-deepspeed-pretrain",
      "category": "artificial-intelligence",
      "title": "Pre-training a large language model with Megatron-DeepSpeed on multiple AMD GPUs",
      "date": "24 Jan 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "LLM",
        "AI/ML",
        "Fine-Tuning",
        "PyTorch"
      ],
      "description": "Pre-training a large language model with Megatron-DeepSpeed on multiple AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "stable-diffusion-aitemplate",
      "path": "blogs/artificial-intelligence/stable-diffusion-aitemplate",
      "category": "artificial-intelligence",
      "title": "Efficient image generation with Stable Diffusion models and AITemplate using AMD GPUs",
      "date": "24 Jan 2024",
      "author": "Douglas Jia",
      "thumbnail": "",
      "tags": [
        "AI/ML",
        "GenAI",
        "Diffusion Model"
      ],
      "description": "Efficient image generation with stable diffusion models and AITemplate using AMD GPUs",
      "language": "English",
      "verticals": [
        "AI"
      ]
    },
    {
      "slug": "spmv/part-1",
      "path": "blogs/high-performance-computing/spmv/part-1",
      "category": "high-performance-computing",
      "title": "Sparse matrix vector multiplication - part 1",
      "date": "3 Nov 2023",
      "author": "Paul Mullowney",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Linear Algebra",
        "Performance",
        "Scientific Computing"
      ],
      "description": "Sparse matrix vector multiplication - Part 1",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "jacobi",
      "path": "blogs/high-performance-computing/jacobi",
      "category": "high-performance-computing",
      "title": "Jacobi Solver with HIP and OpenMP offloading",
      "date": "15 Sep 2023",
      "author": "Asitav Mishra, Rajat Arora, Justin Chang",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Linear Algebra",
        "OpenMP",
        "Optimization",
        "Performance",
        "Profiling",
        "Scientific Computing"
      ],
      "description": "Finite difference method - Laplacian Part 1",
      "language": "English",
      "verticals": [
        "HPC",
        "Data Science"
      ]
    },
    {
      "slug": "pytorch-tensorflow-env",
      "path": "blogs/software-tools-optimization/pytorch-tensorflow-env",
      "category": "software-tools-optimization",
      "title": "Creating a PyTorch/TensorFlow code environment on AMD GPUs",
      "date": "11 Sep 2023",
      "author": "Yao Fehlis",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "AI/ML",
        "Installation",
        "PyTorch",
        "TensorFlow"
      ],
      "description": "Creating a PyTorch TensorFlow environment on AMD GPUs",
      "language": "English",
      "verticals": [
        "AI",
        "Systems"
      ]
    },
    {
      "slug": "finite-difference/laplacian-part4",
      "path": "blogs/high-performance-computing/finite-difference/laplacian-part4",
      "category": "high-performance-computing",
      "title": "Finite difference method - Laplacian part 4",
      "date": "18 Jul 2023",
      "author": "Justin Chang, Thomas Gibson, Sean Miller",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory",
        "Optimization",
        "Performance",
        "Profiling",
        "Scientific Computing"
      ],
      "description": "Finite difference method - Laplacian Part 4",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems",
        "Data Science"
      ]
    },
    {
      "slug": "gpu-aware-mpi",
      "path": "blogs/software-tools-optimization/gpu-aware-mpi",
      "category": "software-tools-optimization",
      "title": "GPU-aware MPI with ROCm",
      "date": "8 Jun 2023",
      "author": "Mahdieh Ghazimirsaeed, Noel Chalmers, Damon McDougall",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "Compiler",
        "HPC",
        "Installation",
        "Memory",
        "Performance"
      ],
      "description": "GPU-aware MPI with ROCm",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems",
        "Developers"
      ]
    },
    {
      "slug": "register-pressure",
      "path": "blogs/software-tools-optimization/register-pressure",
      "category": "software-tools-optimization",
      "title": "Register pressure in AMD CDNA™2 GPUs",
      "date": "17 May 2023",
      "author": "Alessandro Fanfarillo, Nicholas Curtis",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "Compiler",
        "HPC",
        "Memory",
        "Optimization"
      ],
      "description": "Register pressure",
      "language": "English",
      "verticals": [
        "Developers",
        "HPC",
        "Systems",
        "Data Science"
      ]
    },
    {
      "slug": "finite-difference/laplacian-part3",
      "path": "blogs/high-performance-computing/finite-difference/laplacian-part3",
      "category": "high-performance-computing",
      "title": "Finite difference method - Laplacian part 3",
      "date": "11 May 2023",
      "author": "Justin Chang, Rajat Arora, Thomas Gibson, Sean Miller, Ossian O'Reilly",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "Compiler",
        "HPC",
        "Memory",
        "Optimization",
        "Performance",
        "Profiling",
        "Scientific Computing"
      ],
      "description": "Finite difference method - Laplacian Part 3",
      "language": "English",
      "verticals": [
        "HPC",
        "Developers",
        "Systems",
        "Data Science"
      ]
    },
    {
      "slug": "profilers",
      "path": "blogs/software-tools-optimization/profilers",
      "category": "software-tools-optimization",
      "title": "Introduction to profiling tools for AMD hardware",
      "date": "12 Apr 2023",
      "author": "Thomas Gibson, Noah Wolfe, Gina Sitaraman, Suyash Tandon",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory",
        "Profiling"
      ],
      "description": "Profiling tools",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "mi200-memory-space",
      "path": "blogs/software-tools-optimization/mi200-memory-space",
      "category": "software-tools-optimization",
      "title": "AMD Instinct™ MI200 GPU memory space overview",
      "date": "9 Mar 2023",
      "author": "Sean Miller, Rajat Arora, Gina Sitaraman, Maria Ruiz Varela",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory"
      ],
      "description": "AMD Instinct MI200 GPU memory space overview",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "rocm-installation",
      "path": "blogs/software-tools-optimization/rocm-installation",
      "category": "software-tools-optimization",
      "title": "AMD ROCm™ installation",
      "date": "26 Jan 2023",
      "author": "David Doscher",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Installation"
      ],
      "description": "ROCm installation",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "finite-difference/laplacian-part2",
      "path": "blogs/high-performance-computing/finite-difference/laplacian-part2",
      "category": "high-performance-computing",
      "title": "Finite difference method - Laplacian part 2",
      "date": "4 Jan 2023",
      "author": "Justin Chang, Rajat Arora, Thomas Gibson, Sean Miller, Ossian O'Reilly",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory",
        "Optimization",
        "Performance",
        "Profiling",
        "Scientific Computing"
      ],
      "description": "Finite difference method - Laplacian Part 2",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems",
        "Data Science"
      ]
    },
    {
      "slug": "finite-difference/laplacian-part1",
      "path": "blogs/high-performance-computing/finite-difference/laplacian-part1",
      "category": "high-performance-computing",
      "title": "Finite difference method - Laplacian part 1",
      "date": "14 Nov 2022",
      "author": "Justin Chang, Rajat Arora, Thomas Gibson, Sean Miller, Ossian O'Reilly",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "HPC",
        "Memory",
        "Performance",
        "Profiling",
        "Scientific Computing"
      ],
      "description": "Finite difference method - Laplacian Part 1",
      "language": "English",
      "verticals": [
        "HPC",
        "Systems"
      ]
    },
    {
      "slug": "matrix-cores",
      "path": "blogs/software-tools-optimization/matrix-cores",
      "category": "software-tools-optimization",
      "title": "AMD matrix cores",
      "date": "14 Nov 2022",
      "author": "Gina Sitaraman, Damon McDougall, Rene Van Oostrum, Nicholas Malaya, Noel Chalmers, Ossian O'Reilly, Daniel Velicka",
      "thumbnail": "2025-10-20-rocm-hpc-blogs.png",
      "tags": [
        "Compiler",
        "Linear Algebra",
        "Memory",
        "HPC",
        "Optimization"
      ],
      "description": "Matrix cores",
      "language": "English",
      "verticals": [
        "Data Science",
        "Developers",
        "Systems",
        "HPC"
      ]
    }
  ],
  "featuredBlogs": [
    "Scaling AI Inference Performance with vLLM on AMD Instinct MI355X GPUs",
    "Exploring Gameplay Video Generation with Hunyuan-GameCraft on AMD Instinct GPUs",
    "AMD Enterprise AI Suite: Open Infrastructure for Production AI",
    "ROCm 7.9 Technology Preview: ROCm Core SDK and TheRock Build System"
  ]
}